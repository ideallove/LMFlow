Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/datasets/multi_modal_dataset/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/encoder_decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/hf_encoder_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/models/vision2seq_model/index", "autoapi/lmflow/models/vision_encoder/clip_encoder/index", "autoapi/lmflow/models/vision_encoder/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/peft_trainer/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/utils/constants/index", "autoapi/lmflow/utils/conversation_formatter/index", "autoapi/lmflow/utils/conversation_template/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/flash_attention/bloom_flash_attention/index", "autoapi/lmflow/utils/flash_attention/gpt2_flash_attention/index", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index", "autoapi/lmflow/utils/flash_attention/index", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index", "autoapi/lmflow/utils/flash_attention/triton_flash_attention/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/utils/llava_conversation_lib/index", "autoapi/lmflow/utils/multimodal/index", "autoapi/lmflow/utils/position_interpolation/index", "autoapi/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch/index", "autoapi/lmflow/version/index", "blogs/benchmark", "blogs/index", "examples/DATASETS", "examples/TASK_GUIDE", "examples/checkpoints", "examples/index", "examples/medical_finetune", "examples/raft", "examples/reward_modeling", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/datasets/multi_modal_dataset/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/hf_encoder_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/models/vision2seq_model/index.rst", "autoapi/lmflow/models/vision_encoder/clip_encoder/index.rst", "autoapi/lmflow/models/vision_encoder/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/peft_trainer/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/utils/constants/index.rst", "autoapi/lmflow/utils/conversation_formatter/index.rst", "autoapi/lmflow/utils/conversation_template/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/flash_attention/bloom_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/gpt2_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/triton_flash_attention/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/utils/llava_conversation_lib/index.rst", "autoapi/lmflow/utils/multimodal/index.rst", "autoapi/lmflow/utils/position_interpolation/index.rst", "autoapi/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch/index.rst", "autoapi/lmflow/version/index.rst", "blogs/benchmark.md", "blogs/index.md", "examples/DATASETS.md", "examples/TASK_GUIDE.md", "examples/checkpoints.md", "examples/index.md", "examples/medical_finetune.md", "examples/raft.md", "examples/reward_modeling.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.multi_modal_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.text_regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.vision2seq_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.vision_encoder.clip_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.vision_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.raft_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.peft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.raft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.conversation_formatter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.conversation_template</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.bloom_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.gpt2_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.gpt_neo_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.llama_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.triton_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.llava_conversation_lib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.multimodal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.position_interpolation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs", "Blogs", "Dataset", "LMFlow Benchmark Guide", "Checkpoints", "Examples", "Finetune", "RAFT", "Reward Modeling", "LMFlow"], "terms": {"shizh": [0, 60], "diao": [0, 60], "rui": [0, 60], "pan": [0, 60], "hanz": [0, 60], "dong": [0, 60], "ka": 0, "shun": 0, "shum": [0, 60], "jipeng": [0, 60], "zhang": [0, 60], "wei": [0, 60], "xiong": [0, 60], "tong": [0, 60], "The": [1, 4, 5, 6, 7, 11, 12, 13, 14, 20, 23, 27, 28, 30, 31, 34, 37, 38, 44, 51, 53, 58, 59, 60], "first": [1, 34, 37, 51, 53, 54, 55, 58, 59], "public": [1, 58], "task": [1, 13, 14, 34, 51, 56, 58], "tune": [1, 7, 13, 14, 26, 28, 34, 51, 57, 58, 59], "instruct": [1, 53, 59], "user": [1, 37, 51, 53, 54, 58, 60], "defin": [1, 4, 5, 6, 7, 34, 53], "dataset": [1, 3, 4, 8, 13, 14, 19, 24, 26, 27, 28, 30, 31, 34, 38, 51, 56, 57, 59, 60], "A": [1, 5, 6, 11, 12, 13, 14, 19, 20, 24, 26, 27, 31, 34, 38, 46, 51, 58, 59], "simpl": [1, 34, 51, 58, 59, 60], "extens": [1, 58, 60], "api": [1, 37, 51, 60], "develop": [1, 51, 58], "effici": [1, 51, 58, 60], "finetun": [1, 3, 8, 29, 51, 53, 55, 60], "lora": [1, 13, 14, 56, 59, 60], "simplifi": [1, 27, 28, 30, 31, 59, 60], "model": [1, 3, 4, 7, 8, 24, 26, 27, 28, 30, 31, 33, 34, 37, 47, 51, 53, 55, 56, 57, 60], "infer": [1, 4, 13, 14, 19, 20, 27, 30, 53, 58, 60], "framework": [1, 52, 58, 59], "changelog": [2, 60], "version": [2, 3, 4, 8, 44, 46, 51], "0": [2, 8, 13, 20, 27, 30, 31, 34, 44, 50, 51, 55, 58, 59, 60], "1": [2, 3, 4, 5, 6, 13, 20, 27, 30, 34, 44, 51, 53, 56, 57, 60], "mar": 2, "28": [2, 60], "2023": [2, 51, 60], "contributor": [2, 60], "thi": [3, 4, 5, 6, 7, 11, 12, 13, 14, 31, 34, 38, 44, 51, 53, 54, 58, 59, 60], "page": [3, 51, 60], "contain": [3, 4, 5, 6, 11, 12, 20, 27, 28, 30, 31, 34, 51, 53, 58], "auto": [3, 4], "gener": [3, 4, 7, 13, 14, 18, 20, 27, 30, 31, 34, 38, 44, 51, 55, 56, 58, 59, 60], "document": [3, 34, 51], "lmflow": [3, 52, 53, 56, 57, 58, 59], "multi_modal_dataset": [3, 6, 8], "interfac": [3, 8, 13, 14, 15], "tunabl": [3, 8, 13, 14, 15, 16, 26], "vision_encod": [3, 8, 15], "clip_encod": [3, 8, 15, 22], "auto_model": [3, 8, 15], "base_model": [3, 8, 11, 12, 15, 18, 20], "decoder_model": [3, 8, 13, 15], "encoder_decoder_model": [3, 8, 14, 15], "hf_decoder_model": [3, 8, 15, 30], "hf_encoder_decoder_model": [3, 8, 15], "regression_model": [3, 8, 15, 19], "text_regression_model": [3, 8, 15], "vision2seq_model": [3, 8, 15], "pipelin": [3, 8, 53, 57, 58, 60], "util": [3, 4, 6, 7, 8, 29, 31, 51, 59, 60], "peft_train": [3, 8, 29, 32], "raft_train": [3, 8, 29, 32], "auto_pipelin": [3, 8, 29, 57], "base_align": [3, 8, 29, 31], "base_pipelin": [3, 8, 24, 26, 27, 29, 30], "base_tun": [3, 8, 28, 29], "evalu": [3, 4, 8, 29, 34, 52, 53, 55, 58, 59, 60], "inferenc": [3, 4, 8, 29, 53], "raft_align": [3, 8, 29, 58], "flash_attent": [3, 8, 45], "bloom_flash_attent": [3, 8, 42, 45], "gpt2_flash_attent": [3, 8, 42, 45], "gpt_neo_flash_attent": [3, 8, 42, 45], "llama_flash_attent": [3, 8, 42, 45], "triton_flash_attent": [3, 8, 42, 45], "position_interpol": [3, 8, 45], "llama_rope_scaled_monkey_patch": [3, 8, 45, 48], "constant": [3, 8, 45], "conversation_formatt": [3, 8, 45], "conversation_templ": [3, 8, 45], "data_util": [3, 8, 45], "llava_conversation_lib": [3, 8, 45], "multimod": [3, 8, 45], "arg": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 24, 26, 28, 30, 31, 33, 34, 38, 46, 57], "creat": [3, 5, 6, 10, 11, 12, 17, 20, 25, 27, 33, 34, 56, 58, 59, 60], "sphinx": 3, "autoapi": 3, "script": [4, 34, 55, 57, 58, 59], "dataclass": 4, "modelargu": [4, 27, 28, 30, 31, 57], "datasetargu": [4, 5, 6, 7, 27, 28, 30, 31, 57], "argument": [4, 5, 6, 13, 14, 19, 27, 28, 30, 31, 34, 38, 57], "us": [4, 10, 11, 12, 13, 14, 17, 20, 25, 27, 30, 34, 35, 38, 44, 51, 53, 54, 55, 56, 58, 59, 60], "train": [4, 13, 14, 28, 31, 33, 34, 38, 51, 53, 54, 58, 59, 60], "It": [4, 13, 14, 27, 34, 51, 58, 59, 60], "import": [4, 27, 34, 51, 57, 58, 60], "sever": [4, 13, 14, 34, 38, 51, 53, 54, 56], "includ": [4, 5, 6, 34, 37, 38, 51, 53, 58, 59, 60], "field": [4, 58, 59, 60], "from": [4, 5, 6, 13, 14, 21, 27, 30, 34, 38, 44, 51, 55, 57, 58, 59, 60], "type": [4, 5, 6, 9, 19, 34, 51, 53, 54, 58, 59, 60], "option": [4, 5, 6, 11, 12, 13, 14, 19, 20, 28, 30, 31, 34, 44, 51, 55, 58], "require_vers": 4, "transform": [4, 7, 13, 14, 20, 33, 34, 37, 57], "model_for_causal_lm_map": 4, "trainingargu": [4, 33, 34], "model_config_class": 4, "i": [4, 6, 7, 13, 14, 20, 24, 26, 27, 30, 31, 34, 37, 44, 51, 53, 55, 58, 59, 60], "assign": [4, 58], "list": [4, 5, 6, 13, 14, 20, 34, 37, 38, 46, 53, 58, 60], "config": [4, 20, 21, 47, 57, 59], "model_typ": 4, "tupl": [4, 20, 34, 37, 39, 40, 43], "extract": [4, 38, 58], "sourc": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 58, 60], "decor": 4, "paramet": [4, 5, 6, 13, 14, 19, 27, 28, 30, 31, 34, 38, 56, 59, 60], "can": [4, 13, 14, 34, 51, 53, 54, 55, 58, 59, 60], "configur": [4, 58], "model_name_or_path": [4, 54, 55, 58, 59], "str": [4, 5, 6, 7, 13, 14, 30, 34, 37, 38, 46, 58], "string": [4, 5, 6, 13, 14, 20, 30, 34, 38, 53], "repres": [4, 5, 6, 13, 14, 27], "path": [4, 13, 14, 19, 20, 34, 54, 55, 57, 58], "name": [4, 13, 14, 19, 23, 34, 38, 44, 51, 53, 54, 58], "pretrain": [4, 13, 14, 34, 51, 55, 60], "checkpoint": [4, 33, 34, 51, 56, 58], "weight": [4, 27, 60], "initi": [4, 5, 6, 13, 14, 19, 27, 28, 30, 31, 34, 57, 58, 59], "If": [4, 34, 38, 44, 51, 53, 54, 57, 58, 59, 60], "none": [4, 5, 6, 7, 13, 14, 20, 21, 27, 28, 31, 33, 34, 37, 38, 39, 40, 41, 43, 44, 49, 59], "scratch": 4, "provid": [4, 10, 11, 12, 13, 14, 17, 20, 25, 27, 30, 34, 51, 53, 54, 56, 58, 59, 60], "config_overrid": 4, "default": [4, 5, 6, 13, 14, 30, 34, 38, 58], "set": [4, 13, 14, 34, 38, 51, 53, 55, 56, 58, 59], "overrid": [4, 20, 34], "when": [4, 30, 34, 51, 53, 58, 59], "config_nam": 4, "differ": [4, 5, 6, 13, 14, 34, 37, 44, 46, 51, 53, 55, 58, 59], "tokenizer_nam": 4, "token": [4, 6, 7, 13, 14, 20, 27, 30, 31, 34, 37, 51, 57, 58, 59], "cache_dir": 4, "directori": [4, 13, 14, 27, 34, 53, 58], "where": [4, 27, 51, 53, 58, 59, 60], "download": [4, 51, 53, 54, 55, 58], "huggingfac": [4, 5, 6, 13, 14, 55, 58, 59], "co": [4, 58], "store": [4, 44, 58], "use_fast_token": 4, "bool": [4, 7, 20, 30, 34, 38, 39, 40, 43, 46], "boolean": 4, "indic": [4, 20, 51, 53], "whether": [4, 7, 13, 14, 34, 58, 60], "fast": 4, "back": [4, 58, 59], "librari": [4, 34], "model_revis": 4, "specif": [4, 51, 53, 58, 59, 60], "branch": [4, 54], "tag": [4, 34], "commit": [4, 34], "id": [4, 13, 14, 20], "use_auth_token": 4, "run": [4, 27, 28, 31, 34, 51, 53, 54, 55, 58, 59], "cli": 4, "login": 4, "necessari": [4, 34, 51], "privat": 4, "torch_dtyp": 4, "dtype": [4, 21, 34], "load": [4, 5, 6, 13, 14, 20, 27, 28, 30, 31, 34, 38, 55], "under": [4, 34, 51, 53, 54, 60], "pass": [4, 34, 44, 51, 57, 60], "automat": [4, 9, 23, 34, 52, 53, 58], "deriv": 4, "": [4, 34, 51, 53, 54, 57, 58, 59, 60], "use_ram_optimized_load": [4, 54], "disk": 4, "map": [4, 5, 6, 19, 57, 59], "memori": [4, 58], "enough": 4, "use_int8": 4, "int8": 4, "quantiz": 4, "lora_model_path": [4, 55], "arch_typ": 4, "trust_remote_cod": 4, "use_lora": 4, "use_qlora": 4, "bit": [4, 44, 58, 59], "int": [4, 13, 14, 30, 34, 37, 38, 39, 46, 58, 59], "quant_typ": 4, "double_qu": 4, "lora_r": 4, "lora_alpha": 4, "lora_target_modul": 4, "lora_dropout": 4, "float": [4, 19, 27, 30, 34, 58], "save_aggregated_lora": 4, "use_flash_attent": 4, "truncate_to_model_max_length": 4, "do_rope_sc": 4, "rope_pi_ratio": 4, "rope_ntk_ratio": 4, "__post_init__": 4, "vismodelargu": 4, "base": [4, 6, 7, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 37, 44, 46, 49, 51, 53, 58, 59, 60], "low_resourc": [4, 20], "custom_model": [4, 14], "pretrained_language_projection_path": 4, "custom_vision_model": 4, "image_encoder_name_or_path": [4, 20], "qformer_name_or_path": [4, 20], "llm_model_name_or_path": 4, "use_prompt_cach": [4, 20], "prompt_cache_path": 4, "llava_load": 4, "with_qform": 4, "vision_select_lay": 4, "llava_pretrain_model_path": 4, "save_pretrain_model_path": 4, "languag": [4, 13, 14, 27, 28, 34, 44, 51, 60], "dataset_path": [4, 6, 7, 55, 58, 59], "dataset_nam": [4, 54], "valu": [4, 30, 34, 41, 53, 54, 58], "custom": [4, 34, 53, 58, 59], "is_custom_dataset": 4, "data": [4, 5, 6, 7, 19, 27, 28, 31, 34, 37, 38, 51, 53, 54, 55, 58, 59, 60], "fals": [4, 7, 13, 14, 20, 21, 30, 34, 39, 40, 41, 43, 44, 46, 54, 58, 59], "customized_cache_dir": 4, "cach": [4, 5, 6, 34], "dataset_config_nam": 4, "via": [4, 37, 51, 58], "train_fil": 4, "input": [4, 7, 13, 14, 19, 20, 27, 30, 31, 34, 37, 38, 51, 53, 54, 55, 59], "file": [4, 27, 34, 38, 53, 56, 57, 58, 60], "text": [4, 7, 13, 14, 27, 28, 30, 31, 38, 51, 53, 55, 57, 58, 59, 60], "validation_fil": 4, "perplex": [4, 51], "max_train_sampl": 4, "an": [4, 10, 11, 12, 17, 20, 25, 34, 44, 52, 53, 58, 59, 60], "integ": 4, "maximum": [4, 27, 28, 30, 34], "number": [4, 27, 30, 34, 58, 59], "exampl": [4, 7, 11, 12, 34, 37, 38, 44, 51, 53, 54, 55, 60], "debug": 4, "quicker": 4, "truncat": [4, 59], "max_eval_sampl": 4, "stream": 4, "enabl": [4, 60], "mode": [4, 34, 58], "block_siz": 4, "sequenc": [4, 13, 14, 20, 34, 37, 44, 51], "length": [4, 13, 14, 20, 27, 28, 30, 34, 38, 44, 51, 53], "after": [4, 7, 30, 51, 54, 58], "block": [4, 28, 34], "size": [4, 20, 27, 34, 44, 51, 58, 59], "train_on_prompt": 4, "prompt": [4, 7, 13, 14, 20, 30, 31, 53, 58, 59, 60], "convers": [4, 46, 51, 56, 58, 60], "sharegpt": [4, 51, 53], "disable_conversation_bos_token": 4, "disabl": [4, 58], "bo": 4, "disable_conversation_eos_token": 4, "eo": 4, "also": [4, 11, 12, 27, 34, 51, 54, 58, 59, 60], "some": [4, 27, 34, 51, 54, 58, 59, 60], "addit": [4, 7, 34], "further": [4, 51, 58, 60], "overwrite_cach": 4, "validation_split_percentag": [4, 58, 59], "preprocessing_num_work": 4, "disable_group_text": 4, "demo_example_in_prompt": 4, "explanation_in_prompt": 4, "keep_linebreak": 4, "prompt_structur": [4, 30, 54, 55], "function": [4, 11, 12, 19, 20, 31, 34, 58, 59, 60], "help": [4, 51, 53, 58, 59, 60], "messag": [4, 5, 6, 34, 37, 46, 53], "each": [4, 30, 34, 53, 58, 59], "hint": [4, 5, 6], "metadata": [4, 34, 58], "inform": [4, 5, 6, 27, 34, 58, 59, 60], "about": [4, 34, 51, 58, 59, 60], "group_texts_batch_s": 4, "test_fil": 4, "multimodaldatasetargu": 4, "image_fold": 4, "image_aspect_ratio": 4, "is_multimod": 4, "use_image_start_end": 4, "sep_styl": [4, 46], "finetunerargu": [4, 28], "adapt": [4, 13, 14, 33, 34, 58, 60], "eval_dataset_path": 4, "remove_unused_column": 4, "finetune_part": 4, "save_language_project": 4, "use_lisa": 4, "lisa_activated_lay": 4, "lisa_interval_step": 4, "lisa_layers_attribut": 4, "evaluatorargu": [4, 27], "local_rank": [4, 31], "For": [4, 34, 44, 51, 53, 56, 58, 59, 60], "distribut": [4, 30, 34], "random_shuffl": [4, 38], "use_wandb": [4, 27], "random_se": 4, "output_dir": [4, 34, 55, 58], "mixed_precis": 4, "choic": [4, 38, 51, 58, 59], "bf16": 4, "fp16": 4, "mix": [4, 58], "precis": 4, "deepspe": [4, 13, 14, 34, 54, 55, 57], "json": [4, 5, 6, 34, 37, 38, 53, 54, 55, 57, 58, 59], "e": [4, 30, 31, 34, 38, 44, 53, 54, 58, 60], "g": [4, 34, 53, 58], "ds_config": [4, 13, 14, 54, 55], "alreadi": [4, 34, 51, 53, 58, 59], "dict": [4, 5, 6, 30, 34, 37, 46], "temperatur": [4, 30, 58], "control": [4, 5, 6, 30, 33, 34], "divers": [4, 51, 58], "repetition_penalti": 4, "penal": 4, "repetit": 4, "answer_typ": [4, 27, 38, 54, 55], "evaluate_block_s": 4, "metric": [4, 27, 33, 34, 54, 58], "inference_batch_size_per_devic": [4, 58], "use_accelerator_for_evalu": 4, "max_new_token": [4, 30], "inferencerargu": [4, 30], "devic": [4, 13, 14, 21, 34, 49, 58], "do_sampl": 4, "use_acceler": [4, 13, 14], "raftalignerargu": [4, 31], "raft": [4, 56], "align": [4, 24, 31, 56], "output_reward_path": [4, 31], "output_min_length": [4, 31], "output_max_length": [4, 31], "num_raft_iter": [4, 58], "raft_batch_s": [4, 58], "top_reward_percentag": [4, 58], "collection_strategi": [4, 58], "benchmarkingargu": 4, "lm_evaluation_metr": 4, "pipeline_argument_map": 4, "autoargu": [4, 57], "choos": [4, 34, 51, 58, 59], "get_pipeline_args_class": [4, 57], "python": [5, 6, 7, 51, 54, 55, 60], "code": [5, 6, 7, 21, 30, 34, 51, 60], "method": [5, 6, 13, 14, 27, 34, 51, 58, 60], "manipul": [5, 6], "backend": [5, 6, 13, 14, 34, 44], "hug": [5, 6, 53], "face": [5, 6], "dictionari": [5, 6, 27, 28, 34], "retriev": [5, 6], "dataset_typ": 5, "text_onli": [5, 19, 30, 53, 54, 58, 59], "text2text": [5, 54, 56], "float_onli": 5, "image_text": [5, 30], "key_typ": 5, "key_inst": 5, "instanc": [5, 6, 7, 13, 14, 19, 27, 28, 34, 51, 53, 58, 59, 60], "data_arg": [5, 6, 7, 23, 27, 28, 30, 31, 57], "kwarg": [5, 6, 9, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 26, 28, 31, 33, 34, 37], "object": [5, 6, 7, 19, 27, 28, 30, 31, 34], "given": [5, 6, 19, 27, 28, 30, 31, 34, 51, 54, 58, 59], "requir": [5, 6, 27, 28, 30, 31, 51, 53, 58, 59, 60], "posit": [5, 6, 13, 14, 19, 28, 31, 51, 58, 59, 60], "keyword": [5, 6, 13, 14, 19, 28, 31, 34], "__len__": [5, 6, 7, 34], "_check_data_format": [5, 6], "check": [5, 6, 34, 51, 53], "structur": [5, 6, 58, 59], "match": [5, 6, 51], "rais": [5, 6, 34], "from_dict": [5, 6], "dict_obj": [5, 6], "return": [5, 6, 7, 13, 14, 20, 23, 27, 28, 30, 31, 34, 38, 51, 58, 59], "format": [5, 6, 30, 56], "key_1": [5, 6, 53], "value_1": [5, 6, 53], "key_2": [5, 6, 53], "2": [5, 6, 30, 31, 37, 44, 51, 53, 56, 57, 60], "value_2": [5, 6, 53], "self": [5, 6, 34, 39, 40, 41, 43, 44, 58], "classmethod": [5, 6, 9, 23], "create_from_dict": [5, 6], "to_dict": [5, 6], "to_list": [5, 6], "get_backend": [5, 6], "get_backend_dataset": [5, 6], "backend_dataset": [5, 6], "get_fingerprint": [5, 6], "fingerprint": [5, 6], "which": [5, 6, 13, 14, 24, 26, 27, 34, 51, 53, 58, 59, 60], "get_data_arg": [5, 6], "get_typ": [5, 6], "custommultimodaldataset": [6, 7], "torch": [6, 7, 20, 21, 30, 31, 34, 38, 39, 40, 43, 44, 49], "multi": [6, 7, 51], "modal": [6, 7], "register_token": [6, 7], "image_processor": [6, 7], "__getitem__": [6, 7], "preprocess_multimodal_llava": 7, "tokenizer_image_token": 7, "image_token_index": [7, 20, 35], "return_tensor": 7, "preprocess_llama_from_llava_plain": 7, "pretrainedtoken": [7, 37], "has_imag": 7, "just": [7, 44, 51, 58, 59, 60], "add": [7, 34, 54, 58], "imag": [7, 20, 21, 35], "front": 7, "And": 7, "don": [7, 33, 53, 58, 59], "t": [7, 33, 34, 44, 51, 53, 58, 59], "ani": [7, 13, 34, 51, 53, 58, 59, 60], "process": [7, 13, 14, 20, 27, 28, 30, 31, 34, 51, 53, 56, 57, 58, 59, 60], "ha": [7, 13, 14, 27, 34, 44, 51, 53], "input_id": [7, 13, 20, 21, 30, 59], "label": [7, 20, 21, 34, 51, 58, 59], "preprocess_llama_from_llava_v1": 7, "put": [7, 54], "so": [7, 34, 37, 51, 58, 59, 60], "need": [7, 33, 34, 51, 53, 54, 55, 58, 59, 60], "target": [7, 30, 34, 60], "datacollatorforsuperviseddataset": 7, "collat": [7, 34], "supervis": [7, 56], "fine": [7, 13, 14, 34, 58, 59, 60], "__call__": 7, "internal_vers": 8, "7": [8, 50, 51, 58, 60], "__version__": [8, 50], "get": [9, 19, 31, 34, 51, 54, 55, 56, 57, 59], "correct": [9, 53, 58], "automodel": 9, "get_model": 9, "model_arg": [9, 13, 14, 19, 23, 27, 28, 30, 31, 47, 57], "basemodel": [10, 11, 12, 18, 20, 31], "abc": [10, 11, 12, 17, 20, 25], "helper": [10, 11, 12, 17, 20, 25, 34], "standard": [10, 11, 12, 17, 20, 25], "wai": [10, 11, 12, 17, 20, 25, 34, 51, 53, 54, 55, 58, 59], "inherit": [10, 11, 12, 17, 20, 25, 34], "one": [11, 12, 34, 51, 53, 54, 57, 58, 59], "line": [11, 12, 51], "summari": [11, 12, 34], "program": [11, 12, 38, 58], "termin": [11, 12], "period": [11, 12, 51], "leav": [11, 12, 51, 53, 58], "blank": [11, 12], "rest": [11, 12], "docstr": [11, 12], "should": [11, 12, 21, 34, 37, 44, 51, 53, 58, 59], "overal": [11, 12, 13, 14, 44, 60], "descript": [11, 12, 34, 53, 56], "mai": [11, 12, 34, 51, 53, 54, 58, 59], "brief": [11, 12], "export": [11, 12], "usag": [11, 12, 51], "typic": [11, 12, 51, 58, 59], "foo": [11, 12], "classfoo": [11, 12], "bar": [11, 12], "functionbar": [11, 12], "decodermodel": [11, 13], "encoderdecodermodel": [12, 14], "call": [13, 14, 34, 51, 58], "hfdecodermodel": [13, 14, 27, 30], "wrapper": [13, 14, 34], "around": [13, 14, 51], "__init__": [13, 14], "ar": [13, 14, 34, 44, 51, 53, 54, 55, 58, 59, 60], "take": [13, 14, 27, 31, 34, 58], "tune_strategi": [13, 14], "attent": [13, 14, 20, 44], "mask": [13, 14, 20, 44], "fed": [13, 14, 34], "support": [13, 14, 30, 37, 44, 54, 55, 56], "normal": [13, 14, 27, 51], "allow": [13, 14, 34, 51, 60], "howev": [13, 14, 51, 55, 58, 60], "strategi": [13, 14, 58], "yet": [13, 14, 44], "implement": [13, 14, 34, 44, 51, 54, 58], "conveni": [13, 14, 51, 58, 60], "variou": [13, 14, 34, 53, 60], "nlp": [13, 14, 51], "classif": [13, 14, 34], "question": [13, 14, 31, 51, 53, 60], "answer": [13, 14, 38, 51, 53, 54, 58, 59, 60], "logger": [13, 14, 28, 30, 31, 34, 37], "models_support_flash_attent": 13, "llamaforcausallm": 13, "gptneoforcausallm": 13, "gpt2forcausallm": 13, "bloomforcausallm": 13, "gpu_support_flash_attent": 13, "gpu": [13, 14, 34, 58], "revis": [13, 14, 19], "etc": [13, 14, 19, 33, 34, 51, 58, 60], "configu": [13, 14], "add_special_token": 13, "true": [13, 14, 27, 28, 34, 38, 58, 59], "full": [13, 14, 33, 51, 58, 59, 60], "tokenized_dataset": [13, 14, 28, 57], "without": [13, 34, 51, 58, 59], "lead": [13, 51, 58], "trail": 13, "special": [13, 58, 60], "thei": [13, 34, 51, 53, 58, 59], "begin": [13, 58], "Of": 13, "sentenc": [13, 51], "end": [13, 34, 53], "encod": [13, 14, 27, 53], "perform": [13, 14, 20, 27, 28, 30, 31, 34, 58, 59, 60], "output": [13, 14, 27, 30, 31, 34, 38, 51, 53], "hello": [13, 60], "world": [13, 51, 58], "101": [13, 51], "7592": 13, "1010": 13, "2088": 13, "102": 13, "batch": [13, 20, 27, 34, 38, 44, 58, 59], "attention_mask": [13, 20, 21, 39, 40, 41, 43, 59], "token_type_id": 13, "tensor": [13, 20, 30, 34, 39, 40, 43], "decod": [13, 14, 27, 38, 53], "singl": [13, 34, 46, 51, 53, 58, 59], "merge_lora_weight": [13, 14], "get_peft_without_qlora": 13, "save": [13, 14, 20, 33, 34, 55, 58, 60], "dir": [13, 14, 54], "save_full_model": [13, 14], "get_max_length": [13, 14, 57], "max": [13, 14, 27], "accept": [13, 14, 19, 27, 34, 53, 58], "term": [13, 14, 51, 58], "get_token": [13, 14, 20], "get_backend_model": [13, 14, 20], "hfencoderdecodermodel": 14, "with_deepspe": 14, "pipeline_arg": [14, 23, 57], "abstract": [14, 24, 26, 30], "regress": [18, 19], "regressionmodel": [18, 19, 31], "textregressionmodel": 19, "register_inference_funct": 19, "inference_func": 19, "regist": [19, 44], "result": [19, 51, 58, 59, 60], "onli": [19, 34, 44, 51, 53, 54, 57, 58, 59, 60], "customautovision2seqmodel": 20, "blip2config": 20, "language_model_name_or_path": 20, "blip2forconditionalgener": 20, "vision_model_from_pretrain": 20, "pretrained_path": 20, "qformer_from_pretrain": 20, "language_model_from_pretrain": 20, "vision_feature_select": 20, "image_forward_out": [20, 21], "register_prompt_cach": 20, "prompt_id": 20, "prompt_keys_valu": 20, "udpat": 20, "embed": 20, "reus": [20, 34], "futur": [20, 58], "longtensor": [20, 43], "floattensor": [20, 40], "save_prompt_cach": 20, "load_prompt_cach": 20, "forward": [20, 21, 34, 39, 40, 41, 43, 44, 49], "pixel_valu": 20, "past_key_valu": [20, 21, 43], "inputs_emb": [20, 40, 43], "use_cach": [20, 39, 40, 41, 43], "output_attent": [20, 39, 40, 41, 43], "output_hidden_st": 20, "return_dict": 20, "one_sample_multiple_imag": 20, "modeling_output": 20, "causallmoutputwithpast": 20, "processor_image_token_in_minigpt4": 20, "language_model_input": 20, "batch_siz": [20, 34, 38, 44, 58], "generate_kwarg": 20, "abl": [20, 34, 51, 58, 59], "condit": [20, 44, 51, 53, 58], "shape": [20, 44], "num_channel": 20, "height": [20, 51], "width": 20, "sequence_length": 20, "avoid": [20, 51, 58], "pad": [20, 34], "index": [20, 34, 60], "insert": 20, "flag": 20, "multipl": [20, 44, 51, 58, 60], "caption": 20, "num_capt": 20, "build_vision_tow": [21, 22], "vision_tower_cfg": [21, 22], "clipvisiontow": 21, "vision_tow": 21, "delay_load": 21, "nn": [21, 34, 49, 59], "properti": [21, 51], "dummy_featur": 21, "hidden_s": 21, "num_patch": 21, "load_model": 21, "encode_imag": 21, "language_project": 21, "feature_select": 21, "prepare_inputs_labels_for_multimod": 21, "language_model": 21, "copi": [21, 46, 58], "llava": 21, "polish": 21, "its": [23, 34, 51, 58, 60], "is_package_version_at_least": 23, "package_nam": 23, "min_vers": 23, "pipeline_map": 23, "autopipelin": [23, 57], "design": [23, 60], "get_pipelin": [23, 57], "pipeline_nam": [23, 57], "basetun": [24, 26, 28], "subclass": [24, 26, 34], "basepipelin": [24, 25, 26, 27, 30], "basealign": [24, 31], "_check_if_align": 24, "reward_model": [24, 31], "_check_if_tun": 26, "packag": [27, 56, 60], "constructor": 27, "three": [27, 51, 53, 58], "relat": [27, 58, 59, 60], "evaluator_arg": 27, "other": [27, 34, 44, 51, 53, 58, 59, 60], "two": [27, 34, 46, 51, 54, 58, 59], "create_dataload": [27, 30], "test": [27, 34, 44, 51, 53, 55, 58, 59, 60], "loader": 27, "iter": [27, 30, 31, 34, 58], "over": [27, 51, 53, 58, 59], "mini": 27, "Then": [27, 55, 58, 59], "write": [27, 51], "log": [27, 34, 51, 54], "consol": 27, "bias": 27, "_match": 27, "predicted_answ": 27, "groundtruth": 27, "accuraci": [27, 51, 58, 59, 60], "verbos": 27, "tunablemodel": [27, 28, 30, 57], "_evaluate_acc_with_acceler": 27, "_evaluate_acc_with_deepspe": 27, "_evaluate_ppl": 27, "_evaluate_nl": 27, "neg": [27, 51, 54, 58, 59, 60], "likelihood": [27, 51, 54], "nll": [27, 51, 56], "n": [27, 51, 53, 54, 60], "sum_": 27, "j": [27, 58, 59], "w_i": 27, "ln": 27, "p": [27, 30], "w_": 27, "context_window": 27, "sampl": [27, 30, 34, 51, 53, 58, 59], "th": 27, "here": [27, 34, 37, 51, 58, 59], "start": [27, 34, 44, 53, 58, 59], "p_": 27, "window_length": 27, "finetuner_arg": 28, "group_text": [28, 57], "model_max_length": [28, 57], "group": [28, 34, 57], "togeth": [28, 34, 58, 60], "form": [28, 34, 58], "transform_dataset_in_plac": 28, "data_col": [28, 34], "rstrip_partial_utf8": 30, "supported_dataset_typ": 30, "inferencer_arg": 30, "batchliz": [30, 38], "dataload": [30, 31, 34, 38], "dataset_s": 30, "100": [30, 34, 44, 59], "remove_image_flag": 30, "chatbot_typ": 30, "mini_gpt": 30, "output_dataset": 30, "stream_infer": 30, "context": [30, 34, 51, 58], "token_per_step": 30, "end_str": 30, "input_dataset": 30, "speculativeinferenc": 30, "draft_model_arg": 30, "ref": 30, "arxiv": [30, 58, 59], "2211": 30, "17192v2": 30, "http": [30, 34, 51, 54, 58, 59, 60], "org": [30, 51, 58, 59], "ab": [30, 58, 59], "17192": 30, "target_model_arg": 30, "draft": [30, 34], "static": [30, 34, 44], "score_to_prob": 30, "score": 30, "top_p": 30, "convert": [30, 34, 38, 53, 55], "NOT": 30, "softmax": 30, "probabl": [30, 34, 51, 58, 59], "top": [30, 51, 58], "argmax": 30, "random": [30, 34, 38, 58], "higher": [30, 51, 58], "make": [30, 34, 44, 51, 53, 54, 58, 59, 60], "more": [30, 34, 51, 58, 59, 60], "uniform": 30, "lower": [30, 34, 51], "peakier": 30, "1e": 30, "6": [30, 51, 58, 60], "cumul": 30, "threshold": 30, "adjust": [30, 58, 59], "prob": 30, "num_sampl": 30, "predict_next_token": 30, "num_new_token": 30, "predict": [30, 34, 51], "next": [30, 58], "autoregressive_sampl": 30, "5": [30, 51, 58, 59, 60], "section": [30, 51, 53, 58], "draft_model": 30, "gamma": 30, "verifi": [30, 60], "approxim": 30, "within": 30, "toolinferenc": 30, "1024": [30, 58], "code_exec": 30, "raftalign": 31, "aligner_arg": 31, "raft_aligner_arg": 31, "_initialize_train": 31, "training_arg": [31, 33, 34], "trainer": [31, 33, 34], "_load_dataset": 31, "selected_dataset": 31, "prepar": [31, 34, 54, 58, 59, 60], "everi": [31, 34], "_load_input_dataset": 31, "_clean_text": [31, 58], "_discard_sampl": [31, 58], "_get_batch_dataset_top": 31, "batch_input": 31, "alpha": 31, "iter_id": 31, "16": [31, 44, 59], "48": [31, 44], "infer_batch_s": 31, "8": [31, 51, 58, 60], "generation_kwarg": 31, "_get_batch_dataset_loc": 31, "k": [31, 44, 51, 58, 59], "feed": [31, 34], "reward": [31, 56], "peft": 33, "pefttrain": 33, "_save_checkpoint": [33, 34], "_": 33, "trial": [33, 34, 51, 58, 59], "optim": [33, 34, 58, 60], "folder": 33, "peftsavingcallback": 33, "trainer_callback": [33, 34], "trainercallback": [33, 34], "correctli": [33, 51, 58, 59], "_save": [33, 34], "on_train_end": 33, "state": [33, 34, 51, 58], "trainerst": 33, "trainercontrol": 33, "final": [33, 51], "best": [33, 34, 51, 58, 59], "on_epoch_end": 33, "intermedi": 33, "case": [33, 34, 44, 51, 55, 58, 59], "interrupt": [33, 34], "on_sav": 33, "is_torch_greater_or_equal_than_1_10": 34, "is_torch_less_than_1_11": 34, "_is_native_cpu_amp_avail": 34, "default_callback": 34, "default_progress_callback": 34, "is_sagemaker_mp_post_1_10": 34, "skip_first_batch": 34, "training_args_nam": 34, "bin": 34, "trainer_state_nam": 34, "trainer_st": 34, "optimizer_nam": 34, "pt": 34, "scheduler_nam": 34, "schedul": 34, "scaler_nam": 34, "scaler": 34, "rafttrain": 34, "modeling_util": 34, "pretrainedmodel": 34, "datacol": 34, "train_dataset": [34, 59], "eval_dataset": [34, 59], "tokenization_utils_bas": 34, "pretrainedtokenizerbas": 34, "model_init": 34, "callabl": 34, "compute_metr": 34, "trainer_util": 34, "evalpredict": 34, "callback": 34, "lr_schedul": 34, "lambdalr": 34, "preprocess_logits_for_metr": 34, "featur": [34, 51], "complet": [34, 58, 60], "eval": [34, 58, 59], "loop": 34, "pytorch": 34, "must": [34, 57, 60], "tip": [34, 53], "work": [34, 44, 51, 58, 59, 60], "you": [34, 44, 51, 53, 54, 55, 58, 59, 60], "still": [34, 44, 51, 58, 59, 60], "your": [34, 56, 58, 59], "own": [34, 51, 53, 54, 58, 59, 60], "long": [34, 51, 53, 58], "same": [34, 58, 59], "tweak": 34, "Will": 34, "basic": 34, "tmp_trainer": 34, "current": [34, 51, 53, 54], "element": [34, 51, 60], "default_data_col": 34, "datacollatorwithpad": 34, "otherwis": 34, "iterabledataset": 34, "column": 34, "remov": [34, 58], "note": [34, 51, 54, 60], "fashion": 34, "either": [34, 58], "intern": [34, 51], "ident": 34, "all": [34, 44, 46, 51, 53, 55, 58, 59, 60], "manual": [34, 51, 53], "seed": [34, 38], "epoch": [34, 51, 58, 59], "have": [34, 37, 44, 51, 53, 54, 55, 58, 59, 60], "set_epoch": 34, "rng": 34, "union": 34, "prepend": 34, "kei": [34, 41, 51, 53, 54, 58, 59], "preprocess": [34, 59], "along": 34, "easier": 34, "rerun": 34, "instanti": 34, "new": [34, 44, 51, 54, 58, 59, 60], "zero": 34, "optuna": 34, "rai": 34, "sigopt": 34, "architectur": 34, "accord": [34, 51, 58], "hyper": [34, 56], "layer": 34, "count": [34, 51], "inner": 34, "dropout": [34, 44], "comput": 34, "those": [34, 51, 58], "detail": [34, 51, 54, 56, 58, 59], "want": [34, 54, 58, 59], "remove_callback": 34, "adamw": 34, "get_linear_schedule_with_warmup": 34, "logit": 34, "right": [34, 51, 58], "befor": [34, 58, 60], "them": [34, 51, 53, 54, 55, 58, 59, 60], "step": [34, 54, 56, 58], "onc": [34, 44], "desir": [34, 58, 59], "modif": 34, "made": [34, 51, 58, 59], "reflect": [34, 51], "receiv": 34, "second": [34, 37, 55, 59], "doe": [34, 51, 58, 59, 60], "alwai": [34, 51, 58, 59], "point": [34, 44, 58], "core": 34, "model_wrap": 34, "most": [34, 51, 53, 58, 59], "extern": [34, 51], "wrap": 34, "origin": [34, 51, 55, 58, 59], "again": 34, "distributeddataparallel": 34, "hasn": 34, "been": [34, 44, 51, 58], "is_model_parallel": 34, "switch": [34, 58, 59], "parallel": [34, 44], "mean": [34, 51, 58, 59], "split": [34, 58, 59], "place_model_on_devic": 34, "place": [34, 58, 59], "overridden": 34, "is_in_train": 34, "while": [34, 44, 51, 60], "add_callback": 34, "In": [34, 51, 53, 54, 55, 58, 59], "member": [34, 58], "pop_callback": 34, "found": [34, 51, 58, 60], "error": 34, "pop": 34, "_move_model_to_devic": 34, "_set_signature_columns_if_need": 34, "_remove_unused_column": 34, "_get_collator_with_removed_column": 34, "unus": 34, "_get_train_sampl": 34, "sampler": 34, "get_train_dataload": 34, "inject": 34, "behavior": 34, "_get_eval_sampl": 34, "get_eval_dataload": 34, "get_test_dataload": 34, "test_dataset": 34, "create_optimizer_and_schedul": 34, "num_training_step": 34, "setup": [34, 56, 58], "learn": [34, 58, 59, 60], "rate": [34, 58], "we": [34, 44, 51, 53, 54, 56, 57, 58, 59, 60], "reason": [34, 58, 59], "well": [34, 51, 58, 60], "someth": [34, 51, 58, 59], "els": [34, 57, 58, 59], "init": 34, "through": [34, 51], "create_optim": 34, "create_schedul": 34, "get_optimizer_cls_and_kwarg": 34, "session": 34, "up": [34, 44, 51, 53, 58, 59], "do": [34, 44, 51, 58, 59, 60], "num_exampl": 34, "access": [34, 51, 53, 55, 60], "exist": 34, "estim": 34, "_hp_search_setup": 34, "hp": 34, "search": [34, 58, 60], "_report_to_hp_search": 34, "_tune_save_checkpoint": 34, "call_model_init": 34, "torch_jit_model_ev": 34, "ipex_optimize_model": 34, "float32": 34, "_wrap_model": 34, "resume_from_checkpoint": 34, "ignore_keys_for_ev": 34, "is_first_tim": 34, "main": [34, 54, 57, 58, 60], "entri": 34, "local": [34, 51, 58], "previou": [34, 58, 59], "equal": [34, 51], "last": [34, 53, 58, 59], "present": [34, 58], "resum": 34, "hyperparamet": 34, "ignor": 34, "gather": [34, 58], "dure": [34, 51, 59], "hide": [34, 58, 59], "deprec": 34, "_one_train": 34, "_inner_training_loop": 34, "serv": [34, 51, 58, 60], "time": [34, 51, 53, 58, 59], "updat": [34, 44, 58, 59], "_get_output_dir": 34, "_load_from_checkpoint": 34, "_load_best_model": 34, "_issue_warnings_after_load": 34, "load_result": 34, "_maybe_log_save_evalu": 34, "tr_loss": 34, "_load_rng_stat": 34, "_load_optimizer_and_schedul": 34, "hyperparameter_search": 34, "hp_space": 34, "compute_object": 34, "n_trial": 34, "20": [34, 51, 58], "direct": [34, 60], "minim": 34, "hpsearchbackend": 34, "hp_name": 34, "bestrun": 34, "launch": 34, "quantiti": 34, "determin": [34, 51], "loss": [34, 59], "sum": 34, "warn": 34, "To": [34, 37, 53, 58, 59, 60], "reiniti": 34, "incompat": 34, "space": [34, 58, 59], "default_hp_space_optuna": 34, "default_hp_space_rai": 34, "default_hp_space_sigopt": 34, "depend": [34, 51, 58, 59], "maxim": [34, 60], "default_compute_object": 34, "greater": [34, 51], "pick": 34, "valid": 34, "training_util": 34, "instal": [34, 54], "create_studi": 34, "see": [34, 51, 53, 58, 59], "readthedoc": 34, "io": [34, 51, 58, 60], "en": [34, 51], "stabl": 34, "refer": [34, 54, 56, 58, 60], "studi": [34, 58, 59], "html": [34, 51, 58], "doc": 34, "latest": 34, "api_doc": 34, "execut": [34, 54], "app": 34, "com": [34, 51, 54, 58, 60], "endpoint": 34, "experi": [34, 51, 58, 60], "run_summari": 34, "watch": 34, "_prepare_input": 34, "nest": 34, "handl": [34, 53, 58], "potenti": [34, 51], "compute_loss_context_manag": 34, "manag": 34, "autocast_smart_context_manag": 34, "cache_en": 34, "appropri": [34, 51, 58, 59], "autocast": 34, "situat": [34, 51, 58, 59], "training_step": 34, "unpack": 34, "being": [34, 37, 51, 58, 59], "expect": [34, 51], "compute_loss": 34, "return_output": 34, "how": [34, 51, 53, 56, 58, 59], "By": [34, 55, 58, 60], "is_local_process_zero": 34, "machin": [34, 60], "is_world_process_zero": 34, "global": [34, 58], "go": [34, 51, 55, 58], "save_model": 34, "_internal_cal": 34, "reload": 34, "from_pretrain": 34, "_save_tpu": 34, "state_dict": [34, 47], "store_flo": 34, "_sorted_checkpoint": 34, "checkpoint_prefix": 34, "prefix_checkpoint_dir": 34, "use_mtim": 34, "_rotate_checkpoint": 34, "ignore_kei": 34, "metric_key_prefix": 34, "respons": [34, 38, 51, 58, 59, 60], "wish": 34, "lst": 34, "prefix": [34, 59], "bleu": 34, "eval_bleu": 34, "come": [34, 51], "predictionoutput": 34, "like": [34, 44, 51, 53, 54, 58, 59, 60], "test_bleu": 34, "becaus": [34, 51, 58], "re": [34, 58, 59], "dynam": 34, "concaten": [34, 51], "arrai": [34, 51], "namedtupl": 34, "follow": [34, 53, 54, 58, 59, 60], "np": 34, "ndarrai": 34, "label_id": 34, "evaluation_loop": 34, "prediction_loss_onli": 34, "evalloopoutput": 34, "share": [34, 58, 60], "both": [34, 44, 51, 58, 60], "_nested_gath": 34, "numpi": [34, 38], "_pad_across_process": 34, "pad_index": 34, "recurs": [34, 51], "safe": [34, 51, 58, 59], "prediction_step": 34, "floating_point_op": 34, "oper": 34, "backward": [34, 44], "anoth": [34, 51, 58], "init_git_repo": 34, "at_init": 34, "git": [34, 54, 60], "repo": [34, 54, 58], "hub_model_id": 34, "overwrite_output_dir": 34, "might": [34, 58, 59], "wipe": 34, "out": [34, 44, 51, 58, 59, 60], "create_model_card": 34, "licens": [34, 51, 58], "model_nam": [34, 54], "finetuned_from": 34, "dataset_tag": 34, "dataset_arg": 34, "card": 34, "avail": [34, 51, 53, 54, 60], "applic": [34, 51, 53, 60], "hub": [34, 51], "One": [34, 51], "identifi": 34, "_push_from_checkpoint": 34, "checkpoint_fold": 34, "push_to_hub": 34, "commit_messag": 34, "upload": 34, "push": 34, "finish": [34, 54], "url": [34, 60], "repositori": [34, 51, 60], "track": [34, 53, 58], "progress": 34, "prediction_loop": 34, "_gather_and_numpifi": 34, "_add_sm_patterns_to_gitignor": 34, "sagemak": 34, "pattern": 34, "gitignor": 34, "commonli": [35, 51, 53, 60], "text_only_dataset_descript": 35, "text_only_dataset_detail": 35, "text2text_dataset_descript": 35, "text2text_dataset_detail": 35, "float_only_dataset_descript": 35, "text_only_dataset_long_descrit": 35, "text2text_dataset_long_descrit": 35, "dataset_description_map": 35, "instance_fields_map": 35, "conversation_role_nam": 35, "controller_heart_beat_expir": 35, "30": [35, 51, 58, 60], "worker_heart_beat_interv": 35, "15": 35, "logdir": 35, "ignore_index": 35, "default_image_token": 35, "default_image_patch_token": 35, "im_patch": 35, "default_im_start_token": 35, "im_start": 35, "default_im_end_token": 35, "im_end": 35, "conversationtempl": 37, "encode_convers": 37, "system": [37, 46, 53], "tool": [37, 53, 60], "guarante": [37, 60], "pair": [37, 51, 53, 54], "todo": [37, 57], "conversation_id": [37, 53], "sysinfo1": 37, "tool_1_desc": 37, "role": [37, 46, 51, 53, 58], "human": [37, 51, 54, 58, 59, 60], "m": [37, 44, 51, 53, 58, 59], "gpt": [37, 51, 58, 59, 60], "__encod": 37, "llama2conversationtempl": 37, "info": [37, 54], "round": [37, 51, 58], "llama2": 37, "set_random_se": 38, "cuda": [38, 44], "load_data": 38, "file_nam": 38, "len": [38, 51, 57, 59], "shuffl": 38, "answer_extract": 38, "funtion": 38, "plain": [38, 46], "b": [38, 54], "c": [38, 51], "d": [38, 44, 51, 58, 59], "mutipl": 38, "qa": [38, 51], "process_image_flag": 38, "image_flag": 38, "imageher": 38, "hidden_st": [39, 40, 41, 43], "residu": 39, "alibi": [39, 44], "layer_past": [39, 40, 41], "head_mask": [39, 40, 41], "_prepare_attn_mask": 39, "input_shap": [39, 40, 43], "past_key_values_length": [39, 40, 43], "booltensor": 39, "replace_bloom_attn_with_flash_attn": 39, "encoder_hidden_st": 40, "encoder_attention_mask": 40, "ellipsi": 40, "_prepare_decoder_attention_mask": [40, 43], "replace_gpt2_attn_with_flash_attn": 40, "_attn": 41, "queri": 41, "replace_gpt_neo_attn_with_flash_attn": 41, "position_id": 43, "replace_llama_attn_with_flash_attn": 43, "experiment": [44, 51], "flashattent": 44, "triton": 44, "dev20221202": 44, "mlir": 44, "seem": [44, 58], "doesn": [44, 51, 58], "head": [44, 58], "dimens": 44, "than": [44, 51, 58, 59], "64": [44, 51, 58, 59, 60], "openai": 44, "ll": [44, 58], "fix": 44, "phil": 44, "tillet": 44, "chang": [44, 54, 58], "causal": 44, "non": [44, 58], "cross": 44, "arbitrari": 44, "seqlen": 44, "128": [44, 59], "32": [44, 59, 60], "bia": 44, "speed": 44, "lse": 44, "instead": [44, 51], "l": 44, "much": 44, "faster": [44, 51], "reduc": [44, 58], "spill": 44, "across": 44, "seqlen_k": 44, "deal": 44, "small": [44, 51], "nhead": 44, "caution": 44, "quit": 44, "robust": [44, 60], "sure": [44, 51, 53, 58, 59], "race": 44, "due": [44, 51, 55], "compil": 44, "a100": 44, "plan": [44, 58], "headdim": 44, "done": [44, 57], "test_flash_attn": 44, "py": [44, 54, 55, 58, 59], "test_flash_attn_triton_race_condit": 44, "ve": [44, 58], "mani": [44, 51, 58, 59], "40": [44, 51, 60], "80": [44, 59], "88": [44, 51], "96": [44, 51], "confid": 44, "left": [44, 51], "between": [44, 51], "slower": 44, "slightli": [44, 55], "raggedtensor": 44, "nestedtensor": 44, "_fwd_kernel": 44, "q": [44, 51], "v": 44, "tmp": 44, "softmax_scal": 44, "stride_qb": 44, "stride_qh": 44, "stride_qm": 44, "stride_kb": 44, "stride_kh": 44, "stride_kn": 44, "stride_vb": 44, "stride_vh": 44, "stride_vn": 44, "stride_bb": 44, "stride_bh": 44, "stride_bm": 44, "stride_ob": 44, "stride_oh": 44, "stride_om": 44, "seqlen_q": 44, "seqlen_q_round": 44, "cache_key_seqlen_q": 44, "cache_key_seqlen_k": 44, "bias_typ": 44, "constexpr": 44, "is_caus": 44, "block_headdim": 44, "even_m": 44, "even_n": 44, "even_headdim": 44, "block_m": 44, "block_n": 44, "_bwd_preprocess_do_o_dot": 44, "delta": 44, "stride_dob": 44, "stride_doh": 44, "stride_dom": 44, "_bwd_store_dk_dv": 44, "dk_ptr": 44, "dv_ptr": 44, "dk": 44, "dv": 44, "offs_n": 44, "offs_d": 44, "_bwd_kernel_one_col_block": 44, "start_n": 44, "dq": 44, "stride_dqm": 44, "stride_dkn": 44, "stride_dvn": 44, "atomic_add": 44, "init_to_zero": 44, "_bwd_kernel": 44, "stride_dqb": 44, "stride_dqh": 44, "stride_dkb": 44, "stride_dkh": 44, "stride_dvb": 44, "stride_dvh": 44, "sequence_parallel": 44, "_flash_attn_forward": 44, "_flash_attn_backward": 44, "o": [44, 51, 57], "flashattnqkvpackedfunc": 44, "autograd": 44, "ctx": 44, "qkv": 44, "3": [44, 51, 53, 54, 56, 60], "broadcast": 44, "would": [44, 51, 58, 59], "flash_attn_qkvpacked_func": 44, "flashattnkvpackedfunc": 44, "kv": 44, "flash_attn_kvpacked_func": 44, "flashattnfunc": 44, "flash_attn_func": 44, "separatorstyl": 46, "kwd": 46, "enum": 46, "separ": [46, 54], "style": [46, 51], "mpt": 46, "llama_2": 46, "keep": [46, 58], "histori": [46, 51, 58, 59], "offset": 46, "sep": 46, "sep2": 46, "unknown": 46, "skip_next": 46, "get_prompt": 46, "append_messag": 46, "get_imag": 46, "return_pil": 46, "to_gradio_chatbot": 46, "conv_vicuna_v0": 46, "conv_vicuna_v1": 46, "conv_llama_2": 46, "conv_llava_llama_2": 46, "conv_mpt": 46, "conv_llava_plain": 46, "conv_llava_v0": 46, "conv_llava_v0_mmtag": 46, "conv_llava_v1": 46, "conv_llava_v1_mmtag": 46, "default_convers": 46, "conv_templ": 46, "update_custom_config": 47, "load_llava_pretrain_model": 47, "checkpoint_path": 47, "adapt_llava_model_to_lmflow_typ": 47, "condenserotaryembed": 49, "dim": 49, "pi_ratio": 49, "ntk_ratio": 49, "max_position_embed": 49, "2048": 49, "10000": [49, 58, 59], "x": [49, 51, 58, 59], "seq_len": 49, "replace_llama_with_condens": 49, "9": [51, 54, 60], "larg": [51, 58, 60], "huge": 51, "challeng": [51, 58, 59], "sinc": [51, 53, 58], "breakthrough": 51, "chatgpt": [51, 60], "On": 51, "hand": [51, 58, 60], "research": [51, 58], "engin": [51, 53], "reliabl": [51, 58, 60], "compar": [51, 58, 59, 60], "decid": [51, 54], "certain": [51, 58, 59], "scenario": 51, "monitor": 51, "issu": [51, 55, 58, 60], "forget": 51, "recent": 51, "vicuna": 51, "introduc": [51, 58, 60], "comparison": [51, 58], "chatbot": 51, "arena": 51, "pioneer": 51, "invok": 51, "4": [51, 53, 58, 60], "expens": 51, "neither": 51, "scalabl": [51, 60], "nor": 51, "articl": 51, "cheap": 51, "easi": [51, 58, 59], "aspect": 51, "everyon": 51, "commun": [51, 58, 60], "toolkit": [51, 58, 60], "our": [51, 53, 54, 55, 56, 57, 58, 60], "correspond": [51, 53], "corpu": 51, "itself": 51, "abil": [51, 60], "math": 51, "problem": [51, 56, 58, 59], "solv": 51, "plai": 51, "corpora": 51, "quantit": 51, "idea": [51, 58, 59], "behind": 51, "correl": 51, "essai": 51, "understand": [51, 58, 60], "chess": 51, "master": 51, "memor": 51, "endgam": 51, "chessboard": 51, "besid": 51, "similar": [51, 55, 58], "ppl": 51, "nevertheless": 51, "intrins": 51, "induc": 51, "unfair": 51, "smaller": [51, 58], "vocabulari": 51, "inher": 51, "longer": 51, "level": [51, 60], "thu": 51, "advantag": 51, "involv": [51, 58, 59], "As": [51, 53, 58, 59], "good": [51, 53, 55, 58, 59], "find": [51, 58, 59], "tabl": [51, 54, 58], "tradit": [51, 58], "winogrand": 51, "boolq": 51, "arc_": 51, "hellaswag": 51, "piqa": 51, "obqa": 51, "arc_c": 51, "averag": [51, 60], "bloom": [51, 60], "3b": [51, 58, 59], "58": [51, 58, 59, 60], "61": [51, 60], "59": [51, 60], "52": [51, 58, 59], "70": [51, 60], "42": 51, "53": 51, "1b": 51, "62": 51, "65": [51, 58, 59, 60], "73": [51, 60], "35": [51, 60], "33": 51, "56": [51, 60], "opt": [51, 60], "9b": 51, "66": [51, 60], "67": [51, 60], "76": 51, "37": [51, 60], "34": 51, "13b": [51, 59], "69": [51, 58, 59, 60], "39": [51, 58, 60], "llama": [51, 53, 56, 58, 59, 60], "7b": [51, 55, 58, 59, 60], "78": [51, 60], "41": 51, "68": [51, 60], "74": [51, 60], "79": [51, 58, 59], "44": [51, 60], "86": 51, "228": 51, "245": 51, "134": 51, "135": 51, "85": [51, 60], "215": 51, "81": [51, 59], "237": 51, "130": 51, "129": 51, "200": 51, "224": 51, "125": [51, 58], "124": 51, "82": 51, "198": 51, "220": 51, "97": 51, "123": 51, "167": 51, "71": [51, 58, 59], "214": 51, "121": 51, "113": 51, "153": 51, "207": 51, "119": 51, "57": [51, 60], "83": 51, "109": 51, "figur": [51, 58], "abov": [51, 53, 59], "roughli": 51, "magnitud": 51, "gap": 51, "entail": 51, "comprehens": 51, "summar": 51, "limit": 51, "demonstr": [51, 58, 60], "partial": 51, "sheet": 51, "0501": 51, "optimalscal": [51, 58, 60], "github": [51, 54, 58, 60], "task_guid": 51, "robin": 51, "popular": [51, 58, 59], "try": [51, 58, 59], "onlin": 51, "demo": 51, "especi": 51, "observ": [51, 58, 59, 60], "foundat": [51, 58, 60], "obtain": [51, 55, 58, 59, 60], "gain": [51, 58, 60], "achiev": [51, 58, 60], "better": [51, 58, 60], "en_multi_round_chat": 51, "en_singe_round_chat": 51, "188": 51, "213": 51, "164": 51, "181": 51, "172": 51, "163": 51, "184": 51, "173": 51, "155": 51, "175": 51, "165": 51, "150": 51, "170": 51, "160": 51, "146": 51, "qualit": 51, "turn": [51, 58, 59], "effortlessli": 51, "slight": [51, 59], "mistak": [51, 58], "sometim": [51, 58], "item": [51, 54], "mexican": 51, "food": [51, 58], "cuisin": 51, "recommend": [51, 58, 59], "omit": 51, "r1": 51, "capit": 51, "usa": 51, "unit": [51, 58], "washington": 51, "district": 51, "columbia": 51, "locat": 51, "east": 51, "coast": [51, 58], "countri": 51, "northern": 51, "part": 51, "maryland": 51, "georg": 51, "presid": 51, "feder": 51, "directli": [51, 54, 55, 60], "administ": 51, "govern": 51, "citi": 51, "home": [51, 58, 59], "nation": [51, 58], "landmark": 51, "white": 51, "hous": [51, 58, 59], "capitol": 51, "build": [51, 58, 59, 60], "suprem": 51, "court": 51, "museum": 51, "monument": 51, "cultur": [51, 58, 59], "institut": 51, "virginia": 51, "r2": 51, "scene": 51, "restaur": 51, "american": 51, "classic": 51, "There": [51, 58, 59], "dish": [51, 58], "hamburg": 51, "hot": [51, 58], "dog": 51, "appl": 51, "pie": 51, "seafood": 51, "chesapeak": 51, "bai": 51, "known": 51, "fresh": 51, "crab": 51, "cake": 51, "shrimp": 51, "oyster": 51, "ethnic": 51, "popul": 51, "chines": 51, "japanes": 51, "korean": 51, "barbecu": 51, "pull": 51, "pork": 51, "rib": 51, "brisket": 51, "donut": 51, "famou": 51, "happi": [51, 58, 59], "shop": 51, "varieti": 51, "flavor": 51, "street": 51, "truck": 51, "stand": 51, "falafel": 51, "kebab": 51, "taco": 51, "These": 51, "few": [51, 58, 60], "wide": [51, 60], "rang": [51, 59, 60], "visit": 51, "soul": 51, "southern": 51, "bold": 51, "hearti": 51, "portion": 51, "fri": [51, 58], "chicken": 51, "collard": 51, "green": 51, "macaroni": 51, "chees": 51, "ethiopian": 51, "spici": [51, 58], "injera": 51, "sourdough": 51, "flatbread": 51, "wat": 51, "veget": [51, 58], "stew": 51, "kitfo": 51, "meat": [51, 58], "pasta": 51, "bbq": 51, "thrive": 51, "slow": 51, "cook": [51, 58], "side": [51, 58], "spot": 51, "ben": 51, "chili": 51, "bowl": 51, "pete": 51, "vegetarian": 51, "smoke": 51, "barrel": 51, "diplomaci": 51, "culinari": 51, "indian": 51, "r3": 51, "fifth": 51, "mention": 51, "usual": 51, "flame": 51, "heat": [51, 58, 59], "coal": 51, "often": [51, 58], "marin": 51, "sauc": [51, 58], "coleslaw": 51, "bake": [51, 58], "bean": 51, "corn": 51, "cob": 51, "pit": 51, "smokehous": 51, "joint": 51, "salt": [51, 58], "sovereign": 51, "offer": [51, 58], "delici": 51, "margarita": 51, "adam": 51, "morgan": 51, "authent": 51, "year": [51, 58, 60], "al": 51, "pastor": 51, "grill": 51, "enchilada": 51, "fill": 51, "tortilla": 51, "chile": 51, "relleno": 51, "stuf": 51, "pepper": 51, "el": 51, "comal": 51, "cozi": 51, "littl": 51, "neighborhood": 51, "mole": 51, "rich": 51, "blend": 51, "spice": 51, "chocol": [51, 58], "de": 51, "carnita": 51, "crispi": 51, "queso": 51, "casa": 51, "oaxaca": 51, "upscal": 51, "shaw": 51, "menu": [51, 58], "modern": 51, "cevich": 51, "raw": [51, 53], "fish": 51, "lime": 51, "juic": 51, "negro": 51, "dark": 51, "nogada": 51, "poblano": 51, "walnut": 51, "honei": 51, "king": 51, "chain": 51, "area": [51, 60], "burrito": 51, "afford": [51, 58, 59], "price": 51, "carn": 51, "asada": 51, "quesadilla": 51, "lo": 51, "No": 51, "casual": 51, "adobada": 51, "real": [51, 53], "collect": [51, 58, 60], "183": 51, "english": 51, "total": 51, "447": 51, "break": 51, "q1": 51, "a1": 51, "q2": 51, "a2": 51, "q3": 51, "a3": 51, "ouptut": 51, "common": [51, 53, 60], "sens": 51, "acquir": [51, 60], "factual": 51, "knowledg": [51, 60], "properli": [51, 58], "regard": 51, "degrad": 51, "competit": 51, "arc_easi": 51, "60": [51, 60], "72": [51, 60], "38": 51, "55": [51, 59, 60], "63": [51, 60], "77": 51, "75": [51, 60], "254": 51, "89": 51, "266": 51, "147": 51, "106": 51, "219": 51, "258": 51, "151": 51, "105": 51, "141": 51, "95": 51, "262": 51, "149": 51, "140": 51, "240": 51, "139": 51, "surpris": 51, "actual": [51, 58, 59], "consequ": 51, "hallucin": 51, "tend": [51, 58], "give": [51, 58, 59], "plausibl": 51, "incorrect": 51, "irrelev": 51, "explan": 51, "phenomenon": [51, 58, 59], "attempt": 51, "fit": 51, "suffer": 51, "less": 51, "conjectur": 51, "improv": [51, 58, 59, 60], "brought": 51, "qualiti": [51, 58], "900mb": 51, "wa": [51, 58, 59], "600mb": 51, "suggest": [51, 58], "stage": 51, "critic": 51, "monei": 51, "compet": [51, 60], "show": [51, 56, 58, 59], "possess": 51, "friend": 51, "door": 51, "lock": 51, "smell": 51, "ga": 51, "window": [51, 58], "quickli": [51, 60], "possibl": 51, "fire": [51, 58, 59], "depart": [51, 58], "compani": 51, "flammabl": 51, "danger": 51, "even": [51, 53, 59], "deadli": 51, "ventil": 51, "could": [51, 58, 59], "caus": [51, 58, 59], "explos": 51, "escap": 51, "cannot": 51, "stai": [51, 58], "calm": 51, "wait": 51, "arriv": 51, "injuri": 51, "damag": [51, 58, 59, 60], "yourself": 51, "addition": [51, 58, 59], "illeg": 51, "enter": 51, "permiss": 51, "homeown": 51, "locksmith": 51, "assist": [51, 53, 54, 58, 59], "unabl": 51, "emerg": 51, "servic": 51, "polic": 51, "meantim": 51, "lighter": 51, "leak": 51, "evacu": 51, "immedi": 51, "inde": 51, "injur": [51, 58], "bring": [51, 58], "my": [51, 58, 59], "pet": 51, "ferret": 51, "beauti": 51, "pacif": 51, "island": 51, "attend": 51, "icml": 51, "sorri": [51, 53], "am": [51, 58], "awar": [51, 60], "polici": [51, 58], "confer": 51, "organ": [51, 58, 59], "author": [51, 60], "procedur": [51, 58, 59], "permit": 51, "proper": 51, "carri": [51, 58, 59], "diseas": 51, "peopl": [51, 58, 59, 60], "toxoplasmosi": 51, "salmonellosi": 51, "priorit": 51, "health": 51, "safeti": [51, 58], "crowd": 51, "event": 51, "held": [51, 60], "hawaii": 51, "strictli": 51, "prohibit": 51, "carrier": 51, "rabi": 51, "viru": 51, "eleuth": [51, 54], "ai": [51, 53, 58, 59, 60], "lm": [51, 56], "har": [51, 54], "eleutherai": [51, 54, 58, 59], "loyal": 51, "obei": 51, "ethic": 51, "legal": [51, 60], "gpt4_en_instruct": 51, "alpaca": [51, 53, 55], "222": 51, "211": 51, "206": 51, "180": 51, "quicksort": 51, "ye": [51, 58, 59], "algorithm": [51, 56], "def": [51, 57, 58, 59], "arr": 51, "pivot": 51, "middl": 51, "partit": 51, "sub": 51, "appli": [51, 53, 58, 60], "sort": [51, 58, 59], "unsort": 51, "complex": 51, "although": [51, 58, 59], "practic": 51, "carefulli": [51, 58], "chosen": [51, 54, 58, 59], "subarrai": 51, "produc": 51, "synonym": 51, "word": [51, 53, 58], "down": 51, "advers": 51, "difficulti": 51, "hardship": 51, "troubl": [51, 58, 59], "misfortun": 51, "hard": [51, 58, 59], "unpleas": 51, "circumst": [51, 58, 59], "connot": 51, "difficult": 51, "hostil": 51, "factor": [51, 58], "enemi": 51, "natur": [51, 60], "disast": [51, 58], "mild": 51, "inconveni": 51, "major": 51, "setback": 51, "distress": 51, "financi": 51, "bad": 51, "luck": 51, "ill": 51, "fate": 51, "econom": 51, "social": 51, "struggl": 51, "oppress": 51, "afflict": 51, "calam": 51, "tribul": 51, "10": [51, 58, 59], "describ": 51, "impli": 51, "intens": [51, 58], "battl": 51, "conflict": 51, "obstacl": 51, "injustic": 51, "proceed": 51, "persecut": [51, 58, 59], "order": [51, 53], "project": [51, 58], "000": 51, "filter": [51, 59], "767": 51, "effect": [51, 58, 60], "remain": 51, "too": 51, "nonsens": 51, "incomplet": 51, "domain": [51, 60], "chemistri": 51, "biologi": [51, 60], "fail": 51, "par": 51, "surpass": [51, 60], "now": [51, 53, 55, 58], "Its": [51, 53, 60], "essenti": 51, "lmsy": 51, "benchmark": [52, 56], "open": [52, 54, 60], "llm": [52, 58, 60], "cd": [53, 54, 55, 58], "sh": [53, 54, 55, 58, 59], "replac": [53, 58, 59], "strongli": 53, "encourag": [53, 58], "techniqu": [53, 60], "below": [53, 54, 60], "specifi": [53, 54, 58], "path_to_dataset": 53, "data_1": 53, "data_2": 53, "another_data": 53, "shall": [53, 60], "four": [53, 59], "key_3": 53, "key_4": 53, "value_3": 53, "interpret": 53, "sample_text_1": 53, "sample_text_2": 53, "sample_text_3": 53, "example_dataset": 53, "train_50": 53, "mostli": 53, "sample_input_1": 53, "sample_output_1": 53, "sample_input_2": 53, "sample_output_2": 53, "sample_input_3": 53, "sample_output_3": 53, "test_13": 53, "rapidli": 53, "sft": [53, 56], "system_propmt": 53, "tool_description_1": 53, "tool_description_2": 53, "tool_description_x": 53, "content": 53, "user_input_1": 53, "assistant_response_1": 53, "user_input_2": 53, "assistant_response_2": 53, "pleas": [53, 54, 58, 60], "templat": 53, "empti": 53, "convienc": 53, "respect": [53, 58], "trim": 53, "chat": 53, "inst": 53, "sy": [53, 57], "nyou": 53, "nhello": 53, "hi": [53, 58], "glad": [53, 58, 59], "hear": 53, "nwhat": 53, "weather": [53, 58], "confus": 53, "easili": [54, 60], "fork": 54, "clone": [54, 60], "usernam": 54, "checkout": [54, 58], "conda": [54, 60], "y": [54, 60], "activ": [54, 58, 60], "mpi4pi": [54, 60], "pip": [54, 60], "notic": 54, "mkdir": 54, "mv": 54, "local_datset_group_map": 54, "local_datset_map": 54, "local_datset_answertype_map": 54, "combin": 54, "task_combin": 54, "task_1": 54, "task_2": 54, "rememb": [54, 58], "tee": 54, "log_dir": 54, "err": 54, "integr": 54, "benchamrk": 54, "command": [54, 58, 59, 60], "simpli": [54, 58], "lm_eval_dataset_map": 54, "exact": [54, 58], "similarli": 54, "copyright": 55, "facebookresearch": 55, "offici": 55, "hf": 55, "convert_llama_weights_to_hf": 55, "input_dir": 55, "model_s": 55, "enjoi": [55, 58, 59], "With": 55, "output_model": [55, 58], "run_evaluation_with_lora": 55, "cuda_visible_devic": 55, "diff": 55, "textonli": 56, "introduct": 56, "merg": 56, "overview": 56, "guid": [56, 58, 59], "registr": 56, "hfargumentpars": 57, "tunable_model": 57, "pars": 57, "pipelineargu": 57, "parser": 57, "argv": 57, "endswith": 57, "let": [57, 58, 59, 60], "parse_json_fil": 57, "json_fil": 57, "abspath": 57, "parse_args_into_dataclass": 57, "main_process_first": 57, "desc": 57, "lm_dataset": 57, "tuned_model": 57, "remark": [58, 59, 60], "built": 58, "whose": 58, "commerci": [58, 60], "reinforc": [58, 59], "feedback": [58, 59], "rlhf": [58, 59], "instructgpt": [58, 59, 60], "paper": [58, 59], "2203": [58, 59], "02155": [58, 59], "rank": [58, 59], "neo": [58, 59], "skip": 58, "dahoa": [58, 59], "hh": [58, 59], "consist": [58, 59], "particular": [58, 59, 60], "prefer": [58, 59], "reject": [58, 59], "112k": [58, 59], "12": [58, 59], "5k": [58, 59], "what": [58, 59], "kind": [58, 59], "nois": [58, 59], "did": [58, 59], "dinosaur": [58, 59], "didn": [58, 59], "live": [58, 59], "realli": [58, 59], "sai": [58, 59], "guess": [58, 59], "lot": [58, 59], "read": [58, 59], "amount": [58, 59], "imagin": [58, 59], "cant": [58, 59], "stuff": [58, 59], "know": [58, 59], "facilit": 58, "reformul": 58, "ad": [58, 59], "charact": 58, "repli": 58, "hh_rlhf": [58, 59], "xiongwei": 58, "hh_rlhf_sft": 58, "bui": [58, 59], "protect": [58, 59], "cell": [58, 59], "phone": [58, 59], "pocket": [58, 59], "purs": [58, 59], "But": [58, 59], "quick": [58, 59], "interact": [58, 59], "harm": [58, 59], "parent": [58, 59], "screen": [58, 59], "thing": [58, 59], "off": [58, 59], "won": [58, 59], "anyth": [58, 59], "aren": [58, 59], "thank": [58, 59], "me": [58, 59], "welcom": [58, 59, 60], "salam": [58, 59], "witch": [58, 59], "look": [58, 59], "book": [58, 59], "witchcraft": [58, 59], "histor": [58, 59], "salem": [58, 59], "1692": [58, 59], "interest": [58, 59, 60], "coloni": [58, 59], "america": [58, 59], "excel": [58, 59], "religion": [58, 59], "declin": [58, 59], "magic": [58, 59], "belief": [58, 59], "sixteenth": [58, 59], "seventeenth": [58, 59], "centuri": [58, 59], "england": [58, 59], "keith": [58, 59], "thoma": [58, 59], "otherworld": [58, 59], "anthropologi": [58, 59], "superstit": [58, 59], "jack": [58, 59], "goodi": [58, 59], "popish": [58, 59], "plot": [58, 59], "prelat": [58, 59], "everett": [58, 59], "edit": [58, 59], "run_finetun": [58, 59], "modifi": [58, 59], "project_dir": [58, 59], "num_train_epoch": 58, "learning_r": 58, "2e": 58, "per_device_train_batch_s": 58, "run_finetune_with_lora": [58, 59], "fortun": [58, 59], "former": [58, 59], "rm": [58, 59], "hh_rlhf_rm_train": 58, "heater": [58, 59], "hazard": [58, 59], "tell": [58, 59], "fireplac": [58, 59], "room": [58, 59], "materi": [58, 59], "feel": [58, 59], "touch": [58, 59], "fuel": [58, 59], "surround": [58, 59], "That": [58, 59], "teach": [58, 59, 60], "kid": [58, 59], "fort": [58, 59], "Or": [58, 59], "elabor": [58, 59], "exactli": [58, 59], "mayb": [58, 59], "simplest": [58, 59], "pile": [58, 59], "furnitur": [58, 59], "taller": [58, 59], "sturdier": [58, 59], "fun": [58, 59], "explor": [58, 59], "run_reward_model": [58, 59], "superior": 58, "root": 58, "usr_nam": 58, "hh_rlhf_rm_sft_gptneo_2_7b": 58, "1659": 58, "3e": 58, "eval_step": 58, "400": 58, "load_dataset": [58, 59], "24": [58, 59, 60], "merge_lora": 58, "readi": 58, "clearli": 58, "heavili": 58, "influenc": 58, "data_collect": 58, "subsect": 58, "gpt2": 58, "per": 58, "overwritten": 58, "reader": 58, "rl": 58, "environ": 58, "far": 58, "perfect": 58, "drl": 58, "ppo": 58, "exploit": 58, "theses": 58, "imperfect": 58, "attack": 58, "record": [58, 59], "heavi": 58, "burden": 58, "therefor": [58, 60], "256": 58, "discard": 58, "resourc": 58, "82147": 58, "2k": 58, "adopt": 58, "post": [58, 59], "stext": 58, "strip": 58, "reward_model_or_path": 58, "weqweasda": 58, "hh_rlhf_rm": 58, "get_reward_funct": 58, "run_raft_align": 58, "hh_rlhf_llama": 58, "rlhf_prompt": 58, "hh_rlhf_raft_align": 58, "smoothli": 58, "increas": [58, 59], "signific": [58, 59, 60], "drop": 58, "distinct": 58, "22": 58, "examin": 58, "occasion": 58, "detect": 58, "high": 58, "wors": 58, "eventu": 58, "half": 58, "noisi": 58, "notat": 58, "retrain": 58, "allevi": 58, "goal": [58, 60], "curv": 58, "journei": 58, "randomli": 58, "redund": 58, "suspect": 58, "src": 58, "clean_text": 58, "discard_sampl": 58, "advanc": 58, "contribut": 58, "girlfriend": 58, "tri": 58, "remind": 58, "her": 58, "nice": 58, "tast": 58, "compliment": 58, "kitchen": 58, "she": 58, "appreci": 58, "recip": 58, "great": 58, "spend": 58, "child": 58, "homework": 58, "ask": 58, "why": 58, "motiv": 58, "extra": 58, "privileg": 58, "video": 58, "game": 58, "altern": 58, "incentiv": 58, "grade": 58, "clear": 58, "incent": 58, "meaning": 58, "said": 58, "veri": 58, "think": 58, "exchang": 58, "power": [58, 60], "strongest": 58, "hurrican": 58, "ever": 58, "hit": 58, "u": [58, 60], "katrina": 58, "2005": 58, "1938": 58, "bigger": 58, "stronger": 58, "date": 58, "strong": 58, "storm": 58, "1935": 58, "florida": 58, "review": 58, "had": 58, "were": 58, "categori": 58, "800": 58, "death": 58, "caribbean": 58, "led": 58, "creation": 58, "divis": 58, "ocean": 58, "atmospher": 58, "administr": 58, "firefight": 58, "occup": 58, "definit": 58, "criteria": 58, "judg": 58, "hero": 58, "who": [58, 60], "fight": 58, "rescu": 58, "accid": 58, "sick": 58, "educ": 58, "restor": 58, "societi": 58, "cat": 58, "girl": 58, "scout": 58, "samoa": 58, "cooki": 58, "okai": 58, "visual": 58, "cup": 58, "flour": 58, "teaspoon": 58, "soda": 58, "powder": 58, "sugar": 58, "melt": 58, "butter": 58, "egg": 58, "milk": 58, "chip": 58, "miniatur": 58, "chop": 58, "peanut": 58, "pecan": 58, "heard": 58, "videogam": 58, "metal": 58, "gear": 58, "solid": 58, "phantom": 58, "pain": 58, "releas": [58, 60], "unfinish": 58, "seri": 58, "creator": 58, "hideo": 58, "kojima": 58, "konami": 58, "unusu": 58, "director": 58, "vigil": 58, "overse": 58, "opportun": 58, "he": 58, "studio": 58, "product": [58, 60], "strand": 58, "2020": 58, "brand": 58, "knive": 58, "victorinox": 58, "w\u00fcsthof": 58, "host": 58, "guest": 58, "drink": 58, "rwandan": 58, "mizuzu": 58, "deep": 58, "plantain": 58, "oil": 58, "skillet": 58, "until": 58, "golden": 58, "brown": 58, "jfk": 58, "greatest": 58, "accomplish": 58, "civil": 58, "peac": 58, "corp": 58, "propon": 58, "scienc": 58, "technologi": 58, "reform": 58, "impact": [58, 59], "kennedi": 58, "leader": 58, "inspir": 58, "vision": 58, "care": 58, "poor": 58, "mainstream": 58, "foreign": 58, "univers": 58, "supervisor": 58, "incorrectli": 58, "explain": 58, "someon": 58, "diplomat": 58, "willing": 58, "him": 58, "dedic": 58, "employe": 58, "succe": 58, "capabl": 58, "leadership": 58, "talk": 58, "dai": 58, "hate": 58, "hm": 58, "frustrat": 58, "person": 58, "patient": 58, "isn": 58, "malfunct": 58, "softwar": 58, "bug": 58, "hardwar": 58, "network": 58, "outag": 58, "thankfulli": 58, "resolv": 58, "restart": 58, "10k": 59, "12k": 59, "illustr": 59, "select": 59, "percentag": 59, "build_dataset": 59, "assum": [59, 60], "answer_posit": 59, "answer_neg": 59, "tokenized_po": 59, "tokenized_neg": 59, "chosen_input_id": 59, "chosen_attention_mask": 59, "rejected_input_id": 59, "rejected_attention_mask": 59, "data_fil": 59, "lambda": 59, "512": 59, "idx_gap": 59, "logsigmoid": 59, "chosen_reward": 59, "rejected_reward": 59, "appear": 59, "crucial": [59, 60], "success": 59, "underw": 59, "surprisingli": 59, "moreov": [59, 60], "overfit": 59, "84": 59, "wandb": 59, "ianz2020": 59, "bg677mxa": 59, "ka9v1ywd": 59, "lntwmcyd": 59, "weixiong5237": 59, "t3uwm8yp": 59, "p2ju3r1a": 59, "8fc1rcf8": 59, "7oemwynu": 59, "toolbox": 60, "friendli": 60, "speedi": 60, "entir": 60, "backbon": 60, "galactica": 60, "light": 60, "extrem": 60, "33b": 60, "25mb": 60, "storag": 60, "orient": 60, "whole": 60, "expans": 60, "except": 60, "capac": 60, "attain": 60, "intellig": 60, "convent": 60, "despit": 60, "grow": 60, "cater": 60, "maintain": 60, "lightweight": 60, "thoughtfulli": 60, "publicli": 60, "thoroughli": 60, "enhanc": 60, "profici": 60, "medicin": 60, "mathemat": 60, "subject": 60, "matter": 60, "medic": 60, "emphas": 60, "pubmedqa": 60, "medmcqa": 60, "medqa": 60, "usml": 60, "50": 60, "expert": 60, "87": 60, "90": 60, "175b": 60, "46": 60, "54": 60, "27": 60, "18": 60, "43": 60, "25": 60, "49": 60, "51": 60, "mmlu": 60, "anatomi": 60, "clinic": 60, "colleg": 60, "genet": 60, "profession": 60, "36": 60, "30b": 60, "26": 60, "23": 60, "120b": 60, "21": 60, "176b": 60, "29": 60, "gopher": 60, "280b": 60, "gpt3": 60, "constraint": 60, "unseen": 60, "incorpor": 60, "cue": 60, "relev": 60, "approach": 60, "unlock": 60, "jsonl": 60, "readm": 60, "blog": 60, "excit": 60, "announc": 60, "upcom": 60, "workflow": 60, "among": 60, "aim": 60, "democrat": 60, "platform": 60, "skill": 60, "anyon": 60, "particip": 60, "join": 60, "beginn": 60, "believ": 60, "benefit": 60, "vibrant": 60, "innov": 60, "misc": 60, "kashun": 60, "titl": 60, "publish": 60, "journal": 60, "howpublish": 60, "streamlin": 60, "intend": 60, "li": 60, "sole": 60, "compon": 60, "risk": 60, "liabil": 60, "associ": 60, "technic": 60, "advic": 60, "indirect": 60, "incident": 60, "consequenti": 60, "improp": 60, "highlight": 60, "probabilist": 60, "seek": 60, "reli": 60, "outcom": 60, "account": 60, "relianc": 60, "submit": 60}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [4, 0, 0, "-", "args"], [6, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [15, 0, 0, "-", "models"], [29, 0, 0, "-", "pipeline"], [45, 0, 0, "-", "utils"], [50, 0, 0, "-", "version"]], "lmflow.args": [[4, 2, 1, "", "AutoArguments"], [4, 2, 1, "", "BenchmarkingArguments"], [4, 2, 1, "", "DatasetArguments"], [4, 2, 1, "", "EvaluatorArguments"], [4, 2, 1, "", "FinetunerArguments"], [4, 2, 1, "", "InferencerArguments"], [4, 1, 1, "", "MODEL_CONFIG_CLASSES"], [4, 1, 1, "", "MODEL_TYPES"], [4, 2, 1, "", "ModelArguments"], [4, 2, 1, "", "MultiModalDatasetArguments"], [4, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [4, 2, 1, "", "RaftAlignerArguments"], [4, 2, 1, "", "VisModelArguments"]], "lmflow.args.AutoArguments": [[4, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.BenchmarkingArguments": [[4, 4, 1, "", "dataset_name"], [4, 4, 1, "", "lm_evaluation_metric"]], "lmflow.args.DatasetArguments": [[4, 3, 1, "", "__post_init__"], [4, 4, 1, "", "block_size"], [4, 4, 1, "", "customized_cache_dir"], [4, 4, 1, "", "dataset_config_name"], [4, 4, 1, "", "dataset_name"], [4, 4, 1, "", "dataset_path"], [4, 4, 1, "", "disable_conversation_bos_token"], [4, 4, 1, "", "disable_conversation_eos_token"], [4, 4, 1, "", "disable_group_texts"], [4, 4, 1, "", "group_texts_batch_size"], [4, 4, 1, "", "is_custom_dataset"], [4, 4, 1, "", "keep_linebreaks"], [4, 4, 1, "", "max_eval_samples"], [4, 4, 1, "", "max_train_samples"], [4, 4, 1, "", "overwrite_cache"], [4, 4, 1, "", "preprocessing_num_workers"], [4, 4, 1, "", "streaming"], [4, 4, 1, "", "test_file"], [4, 4, 1, "", "train_file"], [4, 4, 1, "", "train_on_prompt"], [4, 4, 1, "", "validation_file"], [4, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[4, 4, 1, "", "answer_type"], [4, 4, 1, "", "deepspeed"], [4, 4, 1, "", "evaluate_block_size"], [4, 4, 1, "", "inference_batch_size_per_device"], [4, 4, 1, "", "local_rank"], [4, 4, 1, "", "max_new_tokens"], [4, 4, 1, "", "metric"], [4, 4, 1, "", "mixed_precision"], [4, 4, 1, "", "output_dir"], [4, 4, 1, "", "prompt_structure"], [4, 4, 1, "", "random_seed"], [4, 4, 1, "", "random_shuffle"], [4, 4, 1, "", "repetition_penalty"], [4, 4, 1, "", "temperature"], [4, 4, 1, "", "use_accelerator_for_evaluator"], [4, 4, 1, "", "use_wandb"]], "lmflow.args.FinetunerArguments": [[4, 4, 1, "", "eval_dataset_path"], [4, 4, 1, "", "finetune_part"], [4, 4, 1, "", "lisa_activated_layers"], [4, 4, 1, "", "lisa_interval_steps"], [4, 4, 1, "", "lisa_layers_attribute"], [4, 4, 1, "", "remove_unused_columns"], [4, 4, 1, "", "save_language_projection"], [4, 4, 1, "", "use_lisa"]], "lmflow.args.InferencerArguments": [[4, 4, 1, "", "deepspeed"], [4, 4, 1, "", "device"], [4, 4, 1, "", "do_sample"], [4, 4, 1, "", "local_rank"], [4, 4, 1, "", "max_new_tokens"], [4, 4, 1, "", "mixed_precision"], [4, 4, 1, "", "random_seed"], [4, 4, 1, "", "repetition_penalty"], [4, 4, 1, "", "temperature"], [4, 4, 1, "", "use_accelerator"]], "lmflow.args.ModelArguments": [[4, 3, 1, "", "__post_init__"], [4, 4, 1, "id0", "arch_type"], [4, 4, 1, "", "bits"], [4, 4, 1, "", "cache_dir"], [4, 4, 1, "", "config_name"], [4, 4, 1, "", "config_overrides"], [4, 4, 1, "", "do_rope_scaling"], [4, 4, 1, "", "double_quant"], [4, 4, 1, "", "lora_alpha"], [4, 4, 1, "", "lora_dropout"], [4, 4, 1, "", "lora_model_path"], [4, 4, 1, "", "lora_r"], [4, 4, 1, "", "lora_target_modules"], [4, 4, 1, "", "model_name_or_path"], [4, 4, 1, "", "model_revision"], [4, 4, 1, "", "model_type"], [4, 4, 1, "", "quant_type"], [4, 4, 1, "", "rope_ntk_ratio"], [4, 4, 1, "", "rope_pi_ratio"], [4, 4, 1, "", "save_aggregated_lora"], [4, 4, 1, "", "tokenizer_name"], [4, 4, 1, "", "torch_dtype"], [4, 4, 1, "", "truncate_to_model_max_length"], [4, 4, 1, "", "trust_remote_code"], [4, 4, 1, "", "use_auth_token"], [4, 4, 1, "", "use_fast_tokenizer"], [4, 4, 1, "", "use_flash_attention"], [4, 4, 1, "", "use_int8"], [4, 4, 1, "", "use_lora"], [4, 4, 1, "", "use_qlora"], [4, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.MultiModalDatasetArguments": [[4, 4, 1, "", "image_aspect_ratio"], [4, 4, 1, "", "image_folder"], [4, 4, 1, "", "is_multimodal"], [4, 4, 1, "", "sep_style"], [4, 4, 1, "", "use_image_start_end"]], "lmflow.args.RaftAlignerArguments": [[4, 4, 1, "", "collection_strategy"], [4, 4, 1, "", "inference_batch_size_per_device"], [4, 4, 1, "", "num_raft_iteration"], [4, 4, 1, "", "output_max_length"], [4, 4, 1, "", "output_min_length"], [4, 4, 1, "", "output_reward_path"], [4, 4, 1, "", "raft_batch_size"], [4, 4, 1, "", "top_reward_percentage"]], "lmflow.args.VisModelArguments": [[4, 4, 1, "", "custom_model"], [4, 4, 1, "", "custom_vision_model"], [4, 4, 1, "", "image_encoder_name_or_path"], [4, 4, 1, "", "llava_loading"], [4, 4, 1, "", "llava_pretrain_model_path"], [4, 4, 1, "", "llm_model_name_or_path"], [4, 4, 1, "", "low_resource"], [4, 4, 1, "", "pretrained_language_projection_path"], [4, 4, 1, "", "prompt_cache_path"], [4, 4, 1, "", "qformer_name_or_path"], [4, 4, 1, "", "save_pretrain_model_path"], [4, 4, 1, "", "use_prompt_cache"], [4, 4, 1, "", "vision_select_layer"], [4, 4, 1, "", "with_qformer"]], "lmflow.datasets": [[6, 2, 1, "", "CustomMultiModalDataset"], [6, 2, 1, "", "Dataset"], [5, 0, 0, "-", "dataset"], [7, 0, 0, "-", "multi_modal_dataset"]], "lmflow.datasets.CustomMultiModalDataset": [[6, 3, 1, "", "__getitem__"], [6, 3, 1, "", "__len__"], [6, 3, 1, "", "register_tokenizer"]], "lmflow.datasets.Dataset": [[6, 3, 1, "", "__len__"], [6, 3, 1, "", "_check_data_format"], [6, 3, 1, "", "create_from_dict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_fingerprint"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"], [6, 3, 1, "", "to_list"]], "lmflow.datasets.dataset": [[5, 1, 1, "", "DATASET_TYPES"], [5, 2, 1, "", "Dataset"], [5, 1, 1, "", "KEY_INSTANCES"], [5, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[5, 3, 1, "", "__len__"], [5, 3, 1, "", "_check_data_format"], [5, 3, 1, "", "create_from_dict"], [5, 3, 1, "", "from_dict"], [5, 3, 1, "", "get_backend"], [5, 3, 1, "", "get_backend_dataset"], [5, 3, 1, "", "get_data_args"], [5, 3, 1, "", "get_fingerprint"], [5, 3, 1, "", "get_type"], [5, 3, 1, "", "map"], [5, 3, 1, "", "to_dict"], [5, 3, 1, "", "to_list"]], "lmflow.datasets.multi_modal_dataset": [[7, 2, 1, "", "CustomMultiModalDataset"], [7, 2, 1, "", "DataCollatorForSupervisedDataset"], [7, 5, 1, "", "preprocess_llama_from_llava_plain"], [7, 5, 1, "", "preprocess_llama_from_llava_v1"], [7, 5, 1, "", "preprocess_multimodal_llava"], [7, 5, 1, "", "tokenizer_image_token"]], "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset": [[7, 3, 1, "", "__getitem__"], [7, 3, 1, "", "__len__"], [7, 3, 1, "", "register_tokenizer"]], "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset": [[7, 3, 1, "", "__call__"], [7, 4, 1, "", "tokenizer"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "encoder_decoder_model"], [13, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "hf_encoder_decoder_model"], [16, 0, 0, "-", "interfaces"], [18, 0, 0, "-", "regression_model"], [19, 0, 0, "-", "text_regression_model"], [20, 0, 0, "-", "vision2seq_model"], [22, 0, 0, "-", "vision_encoder"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, 2, 1, "", "EncoderDecoderModel"]], "lmflow.models.hf_decoder_model": [[13, 1, 1, "id0", "GPU_SUPPORT_FLASH_ATTENTION"], [13, 2, 1, "", "HFDecoderModel"], [13, 1, 1, "", "MODELS_SUPPORT_FLASH_ATTENTION"], [13, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[13, 3, 1, "", "decode"], [13, 3, 1, "", "encode"], [13, 3, 1, "", "get_backend_model"], [13, 3, 1, "", "get_max_length"], [13, 3, 1, "", "get_peft_without_qlora"], [13, 3, 1, "", "get_tokenizer"], [13, 3, 1, "", "inference"], [13, 3, 1, "", "merge_lora_weights"], [13, 3, 1, "", "save"], [13, 3, 1, "", "tokenize"]], "lmflow.models.hf_encoder_decoder_model": [[14, 2, 1, "", "HFEncoderDecoderModel"], [14, 1, 1, "", "logger"]], "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel": [[14, 3, 1, "", "decode"], [14, 3, 1, "", "encode"], [14, 3, 1, "", "get_backend_model"], [14, 3, 1, "", "get_max_length"], [14, 3, 1, "", "get_tokenizer"], [14, 3, 1, "", "inference"], [14, 3, 1, "", "merge_lora_weights"], [14, 3, 1, "", "save"], [14, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[17, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[17, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[18, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[19, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[19, 3, 1, "", "inference"], [19, 3, 1, "", "register_inference_function"]], "lmflow.models.vision2seq_model": [[20, 2, 1, "", "CustomAutoVision2SeqModel"]], "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel": [[20, 3, 1, "", "forward"], [20, 3, 1, "", "generate"], [20, 3, 1, "", "get_backend_model"], [20, 3, 1, "", "get_tokenizer"], [20, 3, 1, "", "language_model_from_pretrained"], [20, 3, 1, "", "load_prompt_cache"], [20, 3, 1, "", "processor_image_token_in_minigpt4"], [20, 3, 1, "", "qformer_from_pretrained"], [20, 3, 1, "", "register_prompt_cache"], [20, 3, 1, "", "save_prompt_cache"], [20, 3, 1, "", "vision_feature_select"], [20, 3, 1, "", "vision_model_from_pretrained"]], "lmflow.models.vision_encoder": [[22, 5, 1, "", "build_vision_tower"], [21, 0, 0, "-", "clip_encoder"]], "lmflow.models.vision_encoder.clip_encoder": [[21, 2, 1, "", "CLIPVisionTower"], [21, 5, 1, "", "build_vision_tower"]], "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower": [[21, 6, 1, "", "config"], [21, 6, 1, "", "device"], [21, 6, 1, "", "dtype"], [21, 6, 1, "", "dummy_feature"], [21, 3, 1, "", "encode_images"], [21, 3, 1, "", "feature_select"], [21, 3, 1, "", "forward"], [21, 6, 1, "", "hidden_size"], [21, 3, 1, "", "load_model"], [21, 6, 1, "", "num_patches"], [21, 3, 1, "", "prepare_inputs_labels_for_multimodal"]], "lmflow.pipeline": [[23, 0, 0, "-", "auto_pipeline"], [24, 0, 0, "-", "base_aligner"], [25, 0, 0, "-", "base_pipeline"], [26, 0, 0, "-", "base_tuner"], [27, 0, 0, "-", "evaluator"], [28, 0, 0, "-", "finetuner"], [30, 0, 0, "-", "inferencer"], [31, 0, 0, "-", "raft_aligner"], [32, 0, 0, "-", "utils"]], "lmflow.pipeline.auto_pipeline": [[23, 2, 1, "", "AutoPipeline"], [23, 1, 1, "", "PIPELINE_MAPPING"], [23, 5, 1, "", "is_package_version_at_least"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[23, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[24, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[24, 3, 1, "", "_check_if_alignable"], [24, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[25, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[26, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[26, 3, 1, "", "_check_if_tunable"], [26, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[27, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[27, 3, 1, "", "_evaluate_acc_with_accelerator"], [27, 3, 1, "", "_evaluate_acc_with_deepspeed"], [27, 3, 1, "", "_evaluate_nll"], [27, 3, 1, "", "_evaluate_ppl"], [27, 3, 1, "", "_match"], [27, 3, 1, "", "create_dataloader"], [27, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[28, 2, 1, "", "Finetuner"], [28, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[28, 3, 1, "", "group_text"], [28, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[30, 2, 1, "", "Inferencer"], [30, 2, 1, "", "SpeculativeInferencer"], [30, 2, 1, "", "ToolInferencer"], [30, 1, 1, "", "logger"], [30, 5, 1, "", "rstrip_partial_utf8"], [30, 1, 1, "", "supported_dataset_type"]], "lmflow.pipeline.inferencer.Inferencer": [[30, 3, 1, "", "create_dataloader"], [30, 3, 1, "", "inference"], [30, 3, 1, "", "stream_inference"]], "lmflow.pipeline.inferencer.SpeculativeInferencer": [[30, 3, 1, "", "autoregressive_sampling"], [30, 3, 1, "", "inference"], [30, 3, 1, "", "predict_next_token"], [30, 3, 1, "", "sample"], [30, 3, 1, "", "score_to_prob"], [30, 3, 1, "", "stream_inference"]], "lmflow.pipeline.inferencer.ToolInferencer": [[30, 3, 1, "", "code_exec"], [30, 3, 1, "", "inference"]], "lmflow.pipeline.raft_aligner": [[31, 2, 1, "", "RaftAligner"], [31, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[31, 3, 1, "", "_clean_text"], [31, 3, 1, "", "_discard_sample"], [31, 3, 1, "", "_get_batch_dataset_local"], [31, 3, 1, "", "_get_batch_dataset_top"], [31, 3, 1, "", "_initialize_trainer"], [31, 3, 1, "", "_load_dataset"], [31, 3, 1, "", "_load_input_dataset"], [31, 3, 1, "", "align"]], "lmflow.pipeline.utils": [[33, 0, 0, "-", "peft_trainer"], [34, 0, 0, "-", "raft_trainer"]], "lmflow.pipeline.utils.peft_trainer": [[33, 2, 1, "", "PeftSavingCallback"], [33, 2, 1, "", "PeftTrainer"]], "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback": [[33, 3, 1, "", "_save"], [33, 3, 1, "", "on_epoch_end"], [33, 3, 1, "", "on_save"], [33, 3, 1, "", "on_train_end"]], "lmflow.pipeline.utils.peft_trainer.PeftTrainer": [[33, 3, 1, "", "_save_checkpoint"]], "lmflow.pipeline.utils.raft_trainer": [[34, 1, 1, "", "DEFAULT_CALLBACKS"], [34, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [34, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [34, 1, 1, "", "OPTIMIZER_NAME"], [34, 2, 1, "", "RaftTrainer"], [34, 1, 1, "", "SCALER_NAME"], [34, 1, 1, "", "SCHEDULER_NAME"], [34, 1, 1, "", "TRAINER_STATE_NAME"], [34, 1, 1, "", "TRAINING_ARGS_NAME"], [34, 1, 1, "", "_is_native_cpu_amp_available"], [34, 1, 1, "", "is_torch_greater_or_equal_than_1_10"], [34, 1, 1, "", "is_torch_less_than_1_11"], [34, 1, 1, "", "logger"], [34, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[34, 3, 1, "", "_add_sm_patterns_to_gitignore"], [34, 3, 1, "", "_gather_and_numpify"], [34, 3, 1, "", "_get_collator_with_removed_columns"], [34, 3, 1, "", "_get_eval_sampler"], [34, 3, 1, "", "_get_output_dir"], [34, 3, 1, "", "_get_train_sampler"], [34, 3, 1, "", "_hp_search_setup"], [34, 3, 1, "", "_inner_training_loop"], [34, 3, 1, "", "_issue_warnings_after_load"], [34, 3, 1, "", "_load_best_model"], [34, 3, 1, "", "_load_from_checkpoint"], [34, 3, 1, "", "_load_optimizer_and_scheduler"], [34, 3, 1, "", "_load_rng_state"], [34, 3, 1, "", "_maybe_log_save_evaluate"], [34, 3, 1, "", "_move_model_to_device"], [34, 3, 1, "", "_nested_gather"], [34, 3, 1, "", "_one_train"], [34, 3, 1, "", "_pad_across_processes"], [34, 3, 1, "", "_prepare_input"], [34, 3, 1, "", "_prepare_inputs"], [34, 3, 1, "", "_push_from_checkpoint"], [34, 3, 1, "", "_remove_unused_columns"], [34, 3, 1, "", "_report_to_hp_search"], [34, 3, 1, "", "_rotate_checkpoints"], [34, 3, 1, "", "_save"], [34, 3, 1, "", "_save_checkpoint"], [34, 3, 1, "", "_save_tpu"], [34, 3, 1, "", "_set_signature_columns_if_needed"], [34, 3, 1, "", "_sorted_checkpoints"], [34, 3, 1, "", "_tune_save_checkpoint"], [34, 3, 1, "", "_wrap_model"], [34, 3, 1, "", "add_callback"], [34, 3, 1, "", "autocast_smart_context_manager"], [34, 3, 1, "", "call_model_init"], [34, 3, 1, "", "compute_loss"], [34, 3, 1, "", "compute_loss_context_manager"], [34, 3, 1, "", "create_model_card"], [34, 3, 1, "", "create_optimizer"], [34, 3, 1, "", "create_optimizer_and_scheduler"], [34, 3, 1, "", "create_scheduler"], [34, 3, 1, "", "evaluate"], [34, 3, 1, "", "evaluation_loop"], [34, 3, 1, "", "floating_point_ops"], [34, 3, 1, "", "get_eval_dataloader"], [34, 3, 1, "", "get_optimizer_cls_and_kwargs"], [34, 3, 1, "", "get_test_dataloader"], [34, 3, 1, "", "get_train_dataloader"], [34, 3, 1, "", "hyperparameter_search"], [34, 3, 1, "", "init_git_repo"], [34, 3, 1, "", "ipex_optimize_model"], [34, 3, 1, "", "is_local_process_zero"], [34, 3, 1, "", "is_world_process_zero"], [34, 3, 1, "", "log"], [34, 3, 1, "", "num_examples"], [34, 3, 1, "", "pop_callback"], [34, 3, 1, "", "predict"], [34, 3, 1, "", "prediction_loop"], [34, 3, 1, "", "prediction_step"], [34, 3, 1, "", "push_to_hub"], [34, 3, 1, "", "remove_callback"], [34, 3, 1, "", "save_model"], [34, 3, 1, "", "store_flos"], [34, 3, 1, "", "torch_jit_model_eval"], [34, 3, 1, "", "train"], [34, 3, 1, "", "training_step"]], "lmflow.utils": [[35, 0, 0, "-", "constants"], [36, 0, 0, "-", "conversation_formatter"], [37, 0, 0, "-", "conversation_template"], [38, 0, 0, "-", "data_utils"], [42, 0, 0, "-", "flash_attention"], [46, 0, 0, "-", "llava_conversation_lib"], [47, 0, 0, "-", "multimodal"], [48, 0, 0, "-", "position_interpolation"]], "lmflow.utils.constants": [[35, 1, 1, "", "CONTROLLER_HEART_BEAT_EXPIRATION"], [35, 1, 1, "", "CONVERSATION_ROLE_NAMES"], [35, 1, 1, "", "DATASET_DESCRIPTION_MAP"], [35, 1, 1, "", "DEFAULT_IMAGE_PATCH_TOKEN"], [35, 1, 1, "", "DEFAULT_IMAGE_TOKEN"], [35, 1, 1, "", "DEFAULT_IM_END_TOKEN"], [35, 1, 1, "", "DEFAULT_IM_START_TOKEN"], [35, 1, 1, "", "FLOAT_ONLY_DATASET_DESCRIPTION"], [35, 1, 1, "", "IGNORE_INDEX"], [35, 1, 1, "", "IMAGE_TOKEN_INDEX"], [35, 1, 1, "", "INSTANCE_FIELDS_MAP"], [35, 1, 1, "", "LOGDIR"], [35, 1, 1, "", "TEXT2TEXT_DATASET_DESCRIPTION"], [35, 1, 1, "", "TEXT2TEXT_DATASET_DETAILS"], [35, 1, 1, "", "TEXT2TEXT_DATASET_LONG_DESCRITION"], [35, 1, 1, "", "TEXT_ONLY_DATASET_DESCRIPTION"], [35, 1, 1, "", "TEXT_ONLY_DATASET_DETAILS"], [35, 1, 1, "", "TEXT_ONLY_DATASET_LONG_DESCRITION"], [35, 1, 1, "", "WORKER_HEART_BEAT_INTERVAL"]], "lmflow.utils.conversation_template": [[37, 2, 1, "", "ConversationTemplate"], [37, 2, 1, "", "Llama2ConversationTemplate"], [37, 1, 1, "", "logger"]], "lmflow.utils.conversation_template.ConversationTemplate": [[37, 3, 1, "", "__encode"], [37, 3, 1, "", "encode_conversation"]], "lmflow.utils.conversation_template.Llama2ConversationTemplate": [[37, 3, 1, "", "__encode"]], "lmflow.utils.data_utils": [[38, 5, 1, "", "answer_extraction"], [38, 5, 1, "", "batchlize"], [38, 5, 1, "", "load_data"], [38, 5, 1, "", "process_image_flag"], [38, 5, 1, "", "set_random_seed"]], "lmflow.utils.flash_attention": [[39, 0, 0, "-", "bloom_flash_attention"], [40, 0, 0, "-", "gpt2_flash_attention"], [41, 0, 0, "-", "gpt_neo_flash_attention"], [43, 0, 0, "-", "llama_flash_attention"], [44, 0, 0, "-", "triton_flash_attention"]], "lmflow.utils.flash_attention.bloom_flash_attention": [[39, 5, 1, "", "_prepare_attn_mask"], [39, 5, 1, "", "forward"], [39, 5, 1, "", "replace_bloom_attn_with_flash_attn"]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[40, 5, 1, "", "_prepare_decoder_attention_mask"], [40, 5, 1, "", "forward"], [40, 5, 1, "", "replace_gpt2_attn_with_flash_attn"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[41, 5, 1, "", "_attn"], [41, 5, 1, "", "forward"], [41, 5, 1, "", "replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention.llama_flash_attention": [[43, 5, 1, "", "_prepare_decoder_attention_mask"], [43, 5, 1, "", "forward"], [43, 5, 1, "", "replace_llama_attn_with_flash_attn"]], "lmflow.utils.flash_attention.triton_flash_attention": [[44, 2, 1, "", "FlashAttnFunc"], [44, 2, 1, "", "FlashAttnKVPackedFunc"], [44, 2, 1, "", "FlashAttnQKVPackedFunc"], [44, 5, 1, "", "_bwd_kernel"], [44, 5, 1, "", "_bwd_kernel_one_col_block"], [44, 5, 1, "", "_bwd_preprocess_do_o_dot"], [44, 5, 1, "", "_bwd_store_dk_dv"], [44, 5, 1, "", "_flash_attn_backward"], [44, 5, 1, "", "_flash_attn_forward"], [44, 5, 1, "", "_fwd_kernel"], [44, 1, 1, "", "flash_attn_func"], [44, 1, 1, "", "flash_attn_kvpacked_func"], [44, 1, 1, "", "flash_attn_qkvpacked_func"], [44, 5, 1, "", "init_to_zero"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc": [[44, 3, 1, "", "backward"], [44, 3, 1, "", "forward"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc": [[44, 3, 1, "", "backward"], [44, 3, 1, "", "forward"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc": [[44, 3, 1, "", "backward"], [44, 3, 1, "", "forward"]], "lmflow.utils.llava_conversation_lib": [[46, 2, 1, "", "Conversation"], [46, 2, 1, "", "SeparatorStyle"], [46, 1, 1, "", "conv_llama_2"], [46, 1, 1, "", "conv_llava_llama_2"], [46, 1, 1, "", "conv_llava_plain"], [46, 1, 1, "", "conv_llava_v0"], [46, 1, 1, "", "conv_llava_v0_mmtag"], [46, 1, 1, "", "conv_llava_v1"], [46, 1, 1, "", "conv_llava_v1_mmtag"], [46, 1, 1, "", "conv_mpt"], [46, 1, 1, "", "conv_templates"], [46, 1, 1, "", "conv_vicuna_v0"], [46, 1, 1, "", "conv_vicuna_v1"], [46, 1, 1, "", "default_conversation"]], "lmflow.utils.llava_conversation_lib.Conversation": [[46, 3, 1, "", "append_message"], [46, 3, 1, "", "copy"], [46, 3, 1, "", "dict"], [46, 3, 1, "", "get_images"], [46, 3, 1, "", "get_prompt"], [46, 4, 1, "", "messages"], [46, 4, 1, "", "offset"], [46, 4, 1, "", "roles"], [46, 4, 1, "", "sep"], [46, 4, 1, "", "sep2"], [46, 4, 1, "", "sep_style"], [46, 4, 1, "", "skip_next"], [46, 4, 1, "", "system"], [46, 3, 1, "", "to_gradio_chatbot"], [46, 4, 1, "", "version"]], "lmflow.utils.llava_conversation_lib.SeparatorStyle": [[46, 4, 1, "", "LLAMA_2"], [46, 4, 1, "", "MPT"], [46, 4, 1, "", "PLAIN"], [46, 4, 1, "", "SINGLE"], [46, 4, 1, "", "TWO"]], "lmflow.utils.multimodal": [[47, 5, 1, "", "adapt_llava_model_to_lmflow_type"], [47, 5, 1, "", "load_llava_pretrain_model"], [47, 5, 1, "", "update_custom_config"]], "lmflow.utils.position_interpolation": [[49, 0, 0, "-", "llama_rope_scaled_monkey_patch"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[49, 2, 1, "", "CondenseRotaryEmbedding"], [49, 5, 1, "", "replace_llama_with_condense"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding": [[49, 3, 1, "", "forward"]], "lmflow.version": [[50, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function", "6": "py:property"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "property", "Python property"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 50], "0": 1, "1": [1, 54, 58, 59], "mar": 1, "28": 1, "2023": [1, 52], "about": 2, "api": 3, "refer": [3, 51], "lmflow": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 60], "arg": 4, "modul": [4, 5, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50], "content": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 60], "class": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 37, 44, 46, 49], "attribut": [4, 5, 13, 14, 23, 28, 30, 31, 34, 37, 44, 46], "dataset": [5, 6, 7, 53, 54, 58], "submodul": [6, 8, 15, 16, 22, 29, 32, 42, 45, 48], "packag": [6, 8, 22], "multi_modal_dataset": 7, "function": [7, 21, 22, 23, 30, 38, 39, 40, 41, 43, 44, 47, 49], "subpackag": [8, 15, 29, 45], "model": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 58, 59], "auto_model": 9, "base_model": 10, "decoder_model": 11, "encoder_decoder_model": 12, "hf_decoder_model": 13, "hf_encoder_decoder_model": 14, "interfac": [16, 17], "tunabl": 17, "regression_model": 18, "text_regression_model": 19, "vision2seq_model": 20, "vision_encod": [21, 22], "clip_encod": 21, "pipelin": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "auto_pipelin": 23, "base_align": 24, "base_pipelin": 25, "base_tun": 26, "evalu": [27, 51, 54, 56], "finetun": [28, 56, 57, 58, 59], "inferenc": 30, "raft_align": 31, "util": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "peft_train": 33, "raft_train": 34, "constant": 35, "conversation_formatt": 36, "conversation_templ": 37, "data_util": 38, "flash_attent": [39, 40, 41, 42, 43, 44], "bloom_flash_attent": 39, "gpt2_flash_attent": 40, "gpt_neo_flash_attent": 41, "llama_flash_attent": 43, "triton_flash_attent": 44, "llava_conversation_lib": 46, "multimod": 47, "position_interpol": [48, 49], "llama_rope_scaled_monkey_patch": 49, "benchmark": [51, 54], "an": 51, "automat": 51, "framework": 51, "open": 51, "sourc": 51, "llm": 51, "introduct": [51, 58, 59, 60], "metric": 51, "chat": 51, "perform": 51, "commonsens": 51, "instruct": [51, 60], "follow": 51, "conclus": 51, "blog": 52, "format": 53, "gener": 53, "support": [53, 60], "detail": 53, "textonli": 53, "text2text": 53, "convers": 53, "work": 53, "progress": 53, "auto": 53, "guid": 54, "nll": 54, "task": [54, 60], "set": 54, "setup": 54, "creat": 54, "your": 54, "file": 54, "registr": 54, "2": [54, 58, 59], "lm": 54, "checkpoint": [55, 60], "llama": 55, "exampl": [56, 58, 59], "data": 56, "prepar": 56, "infer": 56, "raft": 58, "descript": 58, "reward": [58, 59], "supervis": [58, 59], "sft": [58, 59], "3": 58, "lora": 58, "merg": 58, "get": 58, "align": 58, "algorithm": 58, "overview": 58, "hyper": 58, "paramet": 58, "end": 58, "note": 58, "step": 59, "featur": 60, "tune": 60, "instal": 60, "vision": 60, "citat": 60, "disclaim": 60, "indic": 60, "tabl": 60}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "API Reference": [[3, "api-reference"]], "lmflow.args": [[4, "module-lmflow.args"]], "Module Contents": [[4, "module-contents"], [5, "module-contents"], [7, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [30, "module-contents"], [31, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [43, "module-contents"], [44, "module-contents"], [46, "module-contents"], [47, "module-contents"], [49, "module-contents"], [50, "module-contents"]], "Classes": [[4, "classes"], [5, "classes"], [6, "classes"], [7, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [30, "classes"], [31, "classes"], [33, "classes"], [34, "classes"], [37, "classes"], [44, "classes"], [46, "classes"], [49, "classes"]], "Attributes": [[4, "attributes"], [5, "attributes"], [13, "attributes"], [14, "attributes"], [23, "attributes"], [28, "attributes"], [30, "attributes"], [31, "attributes"], [34, "attributes"], [37, "attributes"], [44, "attributes"], [46, "attributes"]], "lmflow.datasets.dataset": [[5, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[6, "module-lmflow.datasets"]], "Submodules": [[6, "submodules"], [8, "submodules"], [15, "submodules"], [16, "submodules"], [22, "submodules"], [29, "submodules"], [32, "submodules"], [42, "submodules"], [45, "submodules"], [48, "submodules"]], "Package Contents": [[6, "package-contents"], [8, "package-contents"], [22, "package-contents"]], "lmflow.datasets.multi_modal_dataset": [[7, "module-lmflow.datasets.multi_modal_dataset"]], "Functions": [[7, "functions"], [21, "functions"], [22, "functions"], [23, "functions"], [30, "functions"], [38, "functions"], [39, "functions"], [40, "functions"], [41, "functions"], [43, "functions"], [44, "functions"], [47, "functions"], [49, "functions"]], "lmflow": [[8, "module-lmflow"]], "Subpackages": [[8, "subpackages"], [15, "subpackages"], [29, "subpackages"], [45, "subpackages"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "lmflow.models.vision2seq_model": [[20, "module-lmflow.models.vision2seq_model"]], "lmflow.models.vision_encoder.clip_encoder": [[21, "module-lmflow.models.vision_encoder.clip_encoder"]], "lmflow.models.vision_encoder": [[22, "module-lmflow.models.vision_encoder"]], "lmflow.pipeline.auto_pipeline": [[23, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_aligner": [[24, "module-lmflow.pipeline.base_aligner"]], "lmflow.pipeline.base_pipeline": [[25, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[26, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[27, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[28, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[29, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[30, "module-lmflow.pipeline.inferencer"]], "lmflow.pipeline.raft_aligner": [[31, "module-lmflow.pipeline.raft_aligner"]], "lmflow.pipeline.utils": [[32, "module-lmflow.pipeline.utils"]], "lmflow.pipeline.utils.peft_trainer": [[33, "module-lmflow.pipeline.utils.peft_trainer"]], "lmflow.pipeline.utils.raft_trainer": [[34, "module-lmflow.pipeline.utils.raft_trainer"]], "lmflow.utils.constants": [[35, "module-lmflow.utils.constants"]], "lmflow.utils.conversation_formatter": [[36, "module-lmflow.utils.conversation_formatter"]], "lmflow.utils.conversation_template": [[37, "module-lmflow.utils.conversation_template"]], "}": [[37, "id5"]], "lmflow.utils.data_utils": [[38, "module-lmflow.utils.data_utils"]], "lmflow.utils.flash_attention.bloom_flash_attention": [[39, "module-lmflow.utils.flash_attention.bloom_flash_attention"]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[40, "module-lmflow.utils.flash_attention.gpt2_flash_attention"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[41, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "lmflow.utils.flash_attention": [[42, "module-lmflow.utils.flash_attention"]], "lmflow.utils.flash_attention.llama_flash_attention": [[43, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "lmflow.utils.flash_attention.triton_flash_attention": [[44, "module-lmflow.utils.flash_attention.triton_flash_attention"]], "lmflow.utils": [[45, "module-lmflow.utils"]], "lmflow.utils.llava_conversation_lib": [[46, "module-lmflow.utils.llava_conversation_lib"]], "lmflow.utils.multimodal": [[47, "module-lmflow.utils.multimodal"]], "lmflow.utils.position_interpolation": [[48, "module-lmflow.utils.position_interpolation"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[49, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch"]], "lmflow.version": [[50, "module-lmflow.version"]], "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs": [[51, "lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms"]], "Introduction": [[51, "introduction"], [59, "introduction"], [60, "introduction"]], "Metric": [[51, "metric"]], "Chat Performance": [[51, "chat-performance"]], "CommonSense Performance": [[51, "commonsense-performance"]], "Instruction Following": [[51, "instruction-following"]], "Conclusion": [[51, "conclusion"]], "References": [[51, "references"]], "Blogs": [[52, "blogs"]], "2023": [[52, "id1"]], "Dataset": [[53, "dataset"]], "Dataset Format in General": [[53, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[53, "supported-dataset-and-detailed-formats"]], "TextOnly": [[53, "textonly"]], "Text2Text": [[53, "text2text"]], "Conversation": [[53, "conversation"]], "Work in Progress": [[53, null]], "Auto Formatting": [[53, null]], "LMFlow Benchmark Guide": [[54, "lmflow-benchmark-guide"]], "1. NLL Task Setting": [[54, "nll-task-setting"]], "Setup": [[54, "setup"]], "Create Your Task Dataset File": [[54, "create-your-task-dataset-file"]], "Task Registration": [[54, "task-registration"]], "2. LM-Evaluation Task Setting": [[54, "lm-evaluation-task-setting"]], "Checkpoints": [[55, "checkpoints"], [60, "checkpoints"]], "LLaMA Checkpoint": [[55, "llama-checkpoint"]], "Examples": [[56, "examples"], [59, "examples"]], "Data preparation": [[56, "data-preparation"]], "Finetuning": [[56, "finetuning"]], "Inference": [[56, "inference"]], "Evaluation": [[56, "evaluation"]], "Finetune": [[57, "finetune"]], "RAFT": [[58, "raft"]], "1 Introduction": [[58, "introduction"]], "1.1 Dataset description": [[58, "dataset-description"]], "2 Reward Modeling": [[58, "reward-modeling"]], "2.1 Supervised Finetuning (SFT)": [[58, "supervised-finetuning-sft"]], "2.2 Reward Modeling": [[58, "id1"]], "2.3 LoRA Merge and Get Reward Model": [[58, "lora-merge-and-get-reward-model"]], "3 RAFT Alignment": [[58, "raft-alignment"]], "3.1 Algorithms Overview": [[58, "algorithms-overview"]], "3.2 Hyper-parameters": [[58, "hyper-parameters"]], "3.3 Examples": [[58, "examples"]], "3.3.1 SFT": [[58, "sft"]], "3.3.2 RAFT Alignment": [[58, "id2"]], "3.3.3 End Note": [[58, "end-note"]], "Reward Modeling": [[59, "reward-modeling"]], "Step 1 Supervised Finetuning (SFT)": [[59, "step-1-supervised-finetuning-sft"]], "Step 2 Reward Modeling": [[59, "step-2-reward-modeling"]], "LMFlow": [[60, "lmflow"]], "Features": [[60, "features"]], "Task Tuning": [[60, "task-tuning"]], "Instruction Tuning": [[60, "instruction-tuning"]], "Installation": [[60, "installation"]], "Content": [[60, "content"]], "Vision": [[60, "vision"]], "Citation": [[60, "citation"]], "Disclaimer": [[60, "disclaimer"]], "Support": [[60, "support"]], "Indices and tables": [[60, "indices-and-tables"]]}, "indexentries": {"autoarguments (class in lmflow.args)": [[4, "lmflow.args.AutoArguments"]], "benchmarkingarguments (class in lmflow.args)": [[4, "lmflow.args.BenchmarkingArguments"]], "datasetarguments (class in lmflow.args)": [[4, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[4, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[4, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[4, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[4, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[4, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[4, "lmflow.args.ModelArguments"]], "multimodaldatasetarguments (class in lmflow.args)": [[4, "lmflow.args.MultiModalDatasetArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[4, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "raftalignerarguments (class in lmflow.args)": [[4, "lmflow.args.RaftAlignerArguments"]], "vismodelarguments (class in lmflow.args)": [[4, "lmflow.args.VisModelArguments"]], "__post_init__() (lmflow.args.datasetarguments method)": [[4, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[4, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.answer_type"]], "arch_type (lmflow.args.modelarguments attribute)": [[4, "id0"], [4, "lmflow.args.ModelArguments.arch_type"]], "bits (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.bits"]], "block_size (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.cache_dir"]], "collection_strategy (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.collection_strategy"]], "config_name (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.config_overrides"]], "custom_model (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.custom_model"]], "custom_vision_model (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.custom_vision_model"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.benchmarkingarguments attribute)": [[4, "lmflow.args.BenchmarkingArguments.dataset_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.deepspeed"]], "device (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.device"]], "disable_conversation_bos_token (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.disable_conversation_bos_token"]], "disable_conversation_eos_token (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.disable_conversation_eos_token"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.disable_group_texts"]], "do_rope_scaling (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.do_rope_scaling"]], "do_sample (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.do_sample"]], "double_quant (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.double_quant"]], "eval_dataset_path (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.eval_dataset_path"]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.evaluate_block_size"]], "finetune_part (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.finetune_part"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[4, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "group_texts_batch_size (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.group_texts_batch_size"]], "image_aspect_ratio (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.image_aspect_ratio"]], "image_encoder_name_or_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.image_encoder_name_or_path"]], "image_folder (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.image_folder"]], "inference_batch_size_per_device (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.inference_batch_size_per_device"]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.is_custom_dataset"]], "is_multimodal (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.is_multimodal"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.keep_linebreaks"]], "lisa_activated_layers (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.lisa_activated_layers"]], "lisa_interval_steps (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.lisa_interval_steps"]], "lisa_layers_attribute (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.lisa_layers_attribute"]], "llava_loading (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.llava_loading"]], "llava_pretrain_model_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.llava_pretrain_model_path"]], "llm_model_name_or_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.llm_model_name_or_path"]], "lm_evaluation_metric (lmflow.args.benchmarkingarguments attribute)": [[4, "lmflow.args.BenchmarkingArguments.lm_evaluation_metric"]], "lmflow.args": [[4, "module-lmflow.args"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_r"]], "lora_target_modules (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_target_modules"]], "low_resource (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.low_resource"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_new_tokens (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.max_new_tokens"]], "max_new_tokens (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.max_new_tokens"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.max_train_samples"]], "metric (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.metric"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.model_type"]], "module": [[4, "module-lmflow.args"], [5, "module-lmflow.datasets.dataset"], [6, "module-lmflow.datasets"], [7, "module-lmflow.datasets.multi_modal_dataset"], [8, "module-lmflow"], [9, "module-lmflow.models.auto_model"], [10, "module-lmflow.models.base_model"], [11, "module-lmflow.models.decoder_model"], [12, "module-lmflow.models.encoder_decoder_model"], [13, "module-lmflow.models.hf_decoder_model"], [14, "module-lmflow.models.hf_encoder_decoder_model"], [15, "module-lmflow.models"], [16, "module-lmflow.models.interfaces"], [17, "module-lmflow.models.interfaces.tunable"], [18, "module-lmflow.models.regression_model"], [19, "module-lmflow.models.text_regression_model"], [20, "module-lmflow.models.vision2seq_model"], [21, "module-lmflow.models.vision_encoder.clip_encoder"], [22, "module-lmflow.models.vision_encoder"], [23, "module-lmflow.pipeline.auto_pipeline"], [24, "module-lmflow.pipeline.base_aligner"], [25, "module-lmflow.pipeline.base_pipeline"], [26, "module-lmflow.pipeline.base_tuner"], [27, "module-lmflow.pipeline.evaluator"], [28, "module-lmflow.pipeline.finetuner"], [29, "module-lmflow.pipeline"], [30, "module-lmflow.pipeline.inferencer"], [31, "module-lmflow.pipeline.raft_aligner"], [32, "module-lmflow.pipeline.utils"], [33, "module-lmflow.pipeline.utils.peft_trainer"], [34, "module-lmflow.pipeline.utils.raft_trainer"], [35, "module-lmflow.utils.constants"], [36, "module-lmflow.utils.conversation_formatter"], [37, "module-lmflow.utils.conversation_template"], [38, "module-lmflow.utils.data_utils"], [39, "module-lmflow.utils.flash_attention.bloom_flash_attention"], [40, "module-lmflow.utils.flash_attention.gpt2_flash_attention"], [41, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"], [42, "module-lmflow.utils.flash_attention"], [43, "module-lmflow.utils.flash_attention.llama_flash_attention"], [44, "module-lmflow.utils.flash_attention.triton_flash_attention"], [45, "module-lmflow.utils"], [46, "module-lmflow.utils.llava_conversation_lib"], [47, "module-lmflow.utils.multimodal"], [48, "module-lmflow.utils.position_interpolation"], [49, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch"], [50, "module-lmflow.version"]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.num_raft_iteration"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.output_dir"]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.output_max_length"]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.output_min_length"]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.output_reward_path"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "pretrained_language_projection_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.pretrained_language_projection_path"]], "prompt_cache_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.prompt_cache_path"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.prompt_structure"]], "qformer_name_or_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.qformer_name_or_path"]], "quant_type (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.quant_type"]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.raft_batch_size"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.random_shuffle"]], "remove_unused_columns (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.remove_unused_columns"]], "repetition_penalty (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.repetition_penalty"]], "repetition_penalty (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.repetition_penalty"]], "rope_ntk_ratio (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.rope_ntk_ratio"]], "rope_pi_ratio (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.rope_pi_ratio"]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.save_aggregated_lora"]], "save_language_projection (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.save_language_projection"]], "save_pretrain_model_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.save_pretrain_model_path"]], "sep_style (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.sep_style"]], "streaming (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.streaming"]], "temperature (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.temperature"]], "temperature (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.temperature"]], "test_file (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.tokenizer_name"]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.top_reward_percentage"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.train_file"]], "train_on_prompt (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.train_on_prompt"]], "truncate_to_model_max_length (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.truncate_to_model_max_length"]], "trust_remote_code (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.trust_remote_code"]], "use_accelerator (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.use_accelerator"]], "use_accelerator_for_evaluator (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_flash_attention (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_flash_attention"]], "use_image_start_end (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.use_image_start_end"]], "use_int8 (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_int8"]], "use_lisa (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.use_lisa"]], "use_lora (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_lora"]], "use_prompt_cache (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.use_prompt_cache"]], "use_qlora (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_qlora"]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_ram_optimized_load"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.validation_split_percentage"]], "vision_select_layer (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.vision_select_layer"]], "with_qformer (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.with_qformer"]], "dataset_types (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.KEY_TYPE"]], "__len__() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.__len__"]], "_check_data_format() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[5, "lmflow.datasets.dataset.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[5, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.to_dict"]], "to_list() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.to_list"]], "custommultimodaldataset (class in lmflow.datasets)": [[6, "lmflow.datasets.CustomMultiModalDataset"]], "dataset (class in lmflow.datasets)": [[6, "lmflow.datasets.Dataset"]], "__getitem__() (lmflow.datasets.custommultimodaldataset method)": [[6, "lmflow.datasets.CustomMultiModalDataset.__getitem__"]], "__len__() (lmflow.datasets.custommultimodaldataset method)": [[6, "lmflow.datasets.CustomMultiModalDataset.__len__"]], "__len__() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.__len__"]], "_check_data_format() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset class method)": [[6, "lmflow.datasets.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_type"]], "lmflow.datasets": [[6, "module-lmflow.datasets"]], "map() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.map"]], "register_tokenizer() (lmflow.datasets.custommultimodaldataset method)": [[6, "lmflow.datasets.CustomMultiModalDataset.register_tokenizer"]], "to_dict() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.to_dict"]], "to_list() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.to_list"]], "custommultimodaldataset (class in lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset"]], "datacollatorforsuperviseddataset (class in lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset"]], "__call__() (lmflow.datasets.multi_modal_dataset.datacollatorforsuperviseddataset method)": [[7, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset.__call__"]], "__getitem__() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.__getitem__"]], "__len__() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.__len__"]], "lmflow.datasets.multi_modal_dataset": [[7, "module-lmflow.datasets.multi_modal_dataset"]], "preprocess_llama_from_llava_plain() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.preprocess_llama_from_llava_plain"]], "preprocess_llama_from_llava_v1() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.preprocess_llama_from_llava_v1"]], "preprocess_multimodal_llava() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.preprocess_multimodal_llava"]], "register_tokenizer() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.register_tokenizer"]], "tokenizer (lmflow.datasets.multi_modal_dataset.datacollatorforsuperviseddataset attribute)": [[7, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset.tokenizer"]], "tokenizer_image_token() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.tokenizer_image_token"]], "__version__ (in module lmflow)": [[8, "lmflow.__version__"]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version"]], "lmflow": [[8, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "encoderdecodermodel (class in lmflow.models.encoder_decoder_model)": [[12, "lmflow.models.encoder_decoder_model.EncoderDecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "gpu_support_flash_attention (in module lmflow.models.hf_decoder_model)": [[13, "id0"], [13, "lmflow.models.hf_decoder_model.GPU_SUPPORT_FLASH_ATTENTION"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "models_support_flash_attention (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.MODELS_SUPPORT_FLASH_ATTENTION"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_peft_without_qlora() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_peft_without_qlora"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "logger (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.save"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "hfencoderdecodermodel (class in lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel"]], "decode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.decode"]], "encode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.inference"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "logger (in module lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.save"]], "tokenize() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.tokenize"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[17, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "regressionmodel (class in lmflow.models.regression_model)": [[18, "lmflow.models.regression_model.RegressionModel"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[19, "lmflow.models.text_regression_model.TextRegressionModel"]], "inference() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.inference"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "register_inference_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.register_inference_function"]], "customautovision2seqmodel (class in lmflow.models.vision2seq_model)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel"]], "forward() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.forward"]], "generate() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.generate"]], "get_backend_model() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.get_backend_model"]], "get_tokenizer() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.get_tokenizer"]], "language_model_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.language_model_from_pretrained"]], "lmflow.models.vision2seq_model": [[20, "module-lmflow.models.vision2seq_model"]], "load_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.load_prompt_cache"]], "processor_image_token_in_minigpt4() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.processor_image_token_in_minigpt4"]], "qformer_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.qformer_from_pretrained"]], "register_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.register_prompt_cache"]], "save_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.save_prompt_cache"]], "vision_feature_select() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.vision_feature_select"]], "vision_model_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[20, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.vision_model_from_pretrained"]], "clipvisiontower (class in lmflow.models.vision_encoder.clip_encoder)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower"]], "build_vision_tower() (in module lmflow.models.vision_encoder.clip_encoder)": [[21, "lmflow.models.vision_encoder.clip_encoder.build_vision_tower"]], "config (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.config"]], "device (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.device"]], "dtype (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.dtype"]], "dummy_feature (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.dummy_feature"]], "encode_images() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.encode_images"]], "feature_select() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.feature_select"]], "forward() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.forward"]], "hidden_size (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.hidden_size"]], "lmflow.models.vision_encoder.clip_encoder": [[21, "module-lmflow.models.vision_encoder.clip_encoder"]], "load_model() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.load_model"]], "num_patches (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.num_patches"]], "prepare_inputs_labels_for_multimodal() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[21, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.prepare_inputs_labels_for_multimodal"]], "build_vision_tower() (in module lmflow.models.vision_encoder)": [[22, "lmflow.models.vision_encoder.build_vision_tower"]], "lmflow.models.vision_encoder": [[22, "module-lmflow.models.vision_encoder"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[23, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[23, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[23, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "is_package_version_at_least() (in module lmflow.pipeline.auto_pipeline)": [[23, "lmflow.pipeline.auto_pipeline.is_package_version_at_least"]], "lmflow.pipeline.auto_pipeline": [[23, "module-lmflow.pipeline.auto_pipeline"]], "basealigner (class in lmflow.pipeline.base_aligner)": [[24, "lmflow.pipeline.base_aligner.BaseAligner"]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[24, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable"]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[24, "lmflow.pipeline.base_aligner.BaseAligner.align"]], "lmflow.pipeline.base_aligner": [[24, "module-lmflow.pipeline.base_aligner"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[25, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[25, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[26, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[26, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[26, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[26, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[27, "lmflow.pipeline.evaluator.Evaluator"]], "_evaluate_acc_with_accelerator() (lmflow.pipeline.evaluator.evaluator method)": [[27, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_accelerator"]], "_evaluate_acc_with_deepspeed() (lmflow.pipeline.evaluator.evaluator method)": [[27, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_deepspeed"]], "_evaluate_nll() (lmflow.pipeline.evaluator.evaluator method)": [[27, "lmflow.pipeline.evaluator.Evaluator._evaluate_nll"]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[27, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[27, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[27, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[27, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[27, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[28, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[28, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[28, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[28, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[28, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[29, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[30, "lmflow.pipeline.inferencer.Inferencer"]], "speculativeinferencer (class in lmflow.pipeline.inferencer)": [[30, "lmflow.pipeline.inferencer.SpeculativeInferencer"]], "toolinferencer (class in lmflow.pipeline.inferencer)": [[30, "lmflow.pipeline.inferencer.ToolInferencer"]], "autoregressive_sampling() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[30, "lmflow.pipeline.inferencer.SpeculativeInferencer.autoregressive_sampling"]], "code_exec() (lmflow.pipeline.inferencer.toolinferencer method)": [[30, "lmflow.pipeline.inferencer.ToolInferencer.code_exec"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[30, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[30, "lmflow.pipeline.inferencer.Inferencer.inference"]], "inference() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[30, "lmflow.pipeline.inferencer.SpeculativeInferencer.inference"]], "inference() (lmflow.pipeline.inferencer.toolinferencer method)": [[30, "lmflow.pipeline.inferencer.ToolInferencer.inference"]], "lmflow.pipeline.inferencer": [[30, "module-lmflow.pipeline.inferencer"]], "logger (in module lmflow.pipeline.inferencer)": [[30, "lmflow.pipeline.inferencer.logger"]], "predict_next_token() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[30, "lmflow.pipeline.inferencer.SpeculativeInferencer.predict_next_token"]], "rstrip_partial_utf8() (in module lmflow.pipeline.inferencer)": [[30, "lmflow.pipeline.inferencer.rstrip_partial_utf8"]], "sample() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[30, "lmflow.pipeline.inferencer.SpeculativeInferencer.sample"]], "score_to_prob() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[30, "lmflow.pipeline.inferencer.SpeculativeInferencer.score_to_prob"]], "stream_inference() (lmflow.pipeline.inferencer.inferencer method)": [[30, "lmflow.pipeline.inferencer.Inferencer.stream_inference"]], "stream_inference() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[30, "lmflow.pipeline.inferencer.SpeculativeInferencer.stream_inference"]], "supported_dataset_type (in module lmflow.pipeline.inferencer)": [[30, "lmflow.pipeline.inferencer.supported_dataset_type"]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner"]], "_clean_text() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner._clean_text"]], "_discard_sample() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner._discard_sample"]], "_get_batch_dataset_local() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_local"]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top"]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer"]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset"]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset"]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[31, "lmflow.pipeline.raft_aligner.RaftAligner.align"]], "lmflow.pipeline.raft_aligner": [[31, "module-lmflow.pipeline.raft_aligner"]], "logger (in module lmflow.pipeline.raft_aligner)": [[31, "lmflow.pipeline.raft_aligner.logger"]], "lmflow.pipeline.utils": [[32, "module-lmflow.pipeline.utils"]], "peftsavingcallback (class in lmflow.pipeline.utils.peft_trainer)": [[33, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback"]], "pefttrainer (class in lmflow.pipeline.utils.peft_trainer)": [[33, "lmflow.pipeline.utils.peft_trainer.PeftTrainer"]], "_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[33, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback._save"]], "_save_checkpoint() (lmflow.pipeline.utils.peft_trainer.pefttrainer method)": [[33, "lmflow.pipeline.utils.peft_trainer.PeftTrainer._save_checkpoint"]], "lmflow.pipeline.utils.peft_trainer": [[33, "module-lmflow.pipeline.utils.peft_trainer"]], "on_epoch_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[33, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_epoch_end"]], "on_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[33, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_save"]], "on_train_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[33, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_train_end"]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS"]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[34, "id0"], [34, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK"]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10"]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME"]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer"]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME"]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME"]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME"]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME"]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore"]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify"]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns"]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler"]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir"]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler"]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup"]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop"]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available"]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load"]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model"]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint"]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler"]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state"]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate"]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device"]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather"]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train"]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes"]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input"]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs"]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint"]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns"]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search"]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints"]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save"]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint"]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu"]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed"]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints"]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint"]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model"]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback"]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager"]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init"]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss"]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager"]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card"]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer"]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler"]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler"]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate"]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop"]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops"]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader"]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs"]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader"]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader"]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search"]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo"]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model"]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero"]], "is_torch_greater_or_equal_than_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.is_torch_greater_or_equal_than_1_10"]], "is_torch_less_than_1_11 (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.is_torch_less_than_1_11"]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero"]], "lmflow.pipeline.utils.raft_trainer": [[34, "module-lmflow.pipeline.utils.raft_trainer"]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log"]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.logger"]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples"]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback"]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict"]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop"]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step"]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub"]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback"]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model"]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[34, "lmflow.pipeline.utils.raft_trainer.skip_first_batches"]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos"]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval"]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train"]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[34, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step"]], "controller_heart_beat_expiration (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.CONTROLLER_HEART_BEAT_EXPIRATION"]], "conversation_role_names (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.CONVERSATION_ROLE_NAMES"]], "dataset_description_map (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.DATASET_DESCRIPTION_MAP"]], "default_image_patch_token (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.DEFAULT_IMAGE_PATCH_TOKEN"]], "default_image_token (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.DEFAULT_IMAGE_TOKEN"]], "default_im_end_token (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.DEFAULT_IM_END_TOKEN"]], "default_im_start_token (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.DEFAULT_IM_START_TOKEN"]], "float_only_dataset_description (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.FLOAT_ONLY_DATASET_DESCRIPTION"]], "ignore_index (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.IGNORE_INDEX"]], "image_token_index (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.IMAGE_TOKEN_INDEX"]], "instance_fields_map (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.INSTANCE_FIELDS_MAP"]], "logdir (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.LOGDIR"]], "text2text_dataset_description (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.TEXT2TEXT_DATASET_DESCRIPTION"]], "text2text_dataset_details (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.TEXT2TEXT_DATASET_DETAILS"]], "text2text_dataset_long_descrition (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.TEXT2TEXT_DATASET_LONG_DESCRITION"]], "text_only_dataset_description (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.TEXT_ONLY_DATASET_DESCRIPTION"]], "text_only_dataset_details (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.TEXT_ONLY_DATASET_DETAILS"]], "text_only_dataset_long_descrition (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.TEXT_ONLY_DATASET_LONG_DESCRITION"]], "worker_heart_beat_interval (in module lmflow.utils.constants)": [[35, "lmflow.utils.constants.WORKER_HEART_BEAT_INTERVAL"]], "lmflow.utils.constants": [[35, "module-lmflow.utils.constants"]], "lmflow.utils.conversation_formatter": [[36, "module-lmflow.utils.conversation_formatter"]], "conversationtemplate (class in lmflow.utils.conversation_template)": [[37, "lmflow.utils.conversation_template.ConversationTemplate"]], "llama2conversationtemplate (class in lmflow.utils.conversation_template)": [[37, "lmflow.utils.conversation_template.Llama2ConversationTemplate"]], "__encode() (lmflow.utils.conversation_template.conversationtemplate method)": [[37, "lmflow.utils.conversation_template.ConversationTemplate.__encode"]], "__encode() (lmflow.utils.conversation_template.llama2conversationtemplate method)": [[37, "lmflow.utils.conversation_template.Llama2ConversationTemplate.__encode"]], "encode_conversation() (lmflow.utils.conversation_template.conversationtemplate method)": [[37, "lmflow.utils.conversation_template.ConversationTemplate.encode_conversation"]], "lmflow.utils.conversation_template": [[37, "module-lmflow.utils.conversation_template"]], "logger (in module lmflow.utils.conversation_template)": [[37, "lmflow.utils.conversation_template.logger"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[38, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[38, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[38, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[38, "lmflow.utils.data_utils.load_data"]], "process_image_flag() (in module lmflow.utils.data_utils)": [[38, "lmflow.utils.data_utils.process_image_flag"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[38, "lmflow.utils.data_utils.set_random_seed"]], "_prepare_attn_mask() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[39, "lmflow.utils.flash_attention.bloom_flash_attention._prepare_attn_mask"]], "forward() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[39, "lmflow.utils.flash_attention.bloom_flash_attention.forward"]], "lmflow.utils.flash_attention.bloom_flash_attention": [[39, "module-lmflow.utils.flash_attention.bloom_flash_attention"]], "replace_bloom_attn_with_flash_attn() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[39, "lmflow.utils.flash_attention.bloom_flash_attention.replace_bloom_attn_with_flash_attn"]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[40, "lmflow.utils.flash_attention.gpt2_flash_attention._prepare_decoder_attention_mask"]], "forward() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[40, "lmflow.utils.flash_attention.gpt2_flash_attention.forward"]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[40, "module-lmflow.utils.flash_attention.gpt2_flash_attention"]], "replace_gpt2_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[40, "lmflow.utils.flash_attention.gpt2_flash_attention.replace_gpt2_attn_with_flash_attn"]], "_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[41, "lmflow.utils.flash_attention.gpt_neo_flash_attention._attn"]], "forward() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[41, "lmflow.utils.flash_attention.gpt_neo_flash_attention.forward"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[41, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "replace_gpt_neo_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[41, "lmflow.utils.flash_attention.gpt_neo_flash_attention.replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention": [[42, "module-lmflow.utils.flash_attention"]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[43, "lmflow.utils.flash_attention.llama_flash_attention._prepare_decoder_attention_mask"]], "forward() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[43, "lmflow.utils.flash_attention.llama_flash_attention.forward"]], "lmflow.utils.flash_attention.llama_flash_attention": [[43, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "replace_llama_attn_with_flash_attn() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[43, "lmflow.utils.flash_attention.llama_flash_attention.replace_llama_attn_with_flash_attn"]], "flashattnfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc"]], "flashattnkvpackedfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc"]], "flashattnqkvpackedfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc"]], "_bwd_kernel() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention._bwd_kernel"]], "_bwd_kernel_one_col_block() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention._bwd_kernel_one_col_block"]], "_bwd_preprocess_do_o_dot() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention._bwd_preprocess_do_o_dot"]], "_bwd_store_dk_dv() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention._bwd_store_dk_dv"]], "_flash_attn_backward() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention._flash_attn_backward"]], "_flash_attn_forward() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention._flash_attn_forward"]], "_fwd_kernel() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention._fwd_kernel"]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnfunc static method)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc.backward"]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnkvpackedfunc static method)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc.backward"]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnqkvpackedfunc static method)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc.backward"]], "flash_attn_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_func"]], "flash_attn_kvpacked_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_kvpacked_func"]], "flash_attn_qkvpacked_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_qkvpacked_func"]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnfunc static method)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc.forward"]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnkvpackedfunc static method)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc.forward"]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnqkvpackedfunc static method)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc.forward"]], "init_to_zero() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[44, "lmflow.utils.flash_attention.triton_flash_attention.init_to_zero"]], "lmflow.utils.flash_attention.triton_flash_attention": [[44, "module-lmflow.utils.flash_attention.triton_flash_attention"]], "lmflow.utils": [[45, "module-lmflow.utils"]], "conversation (class in lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.Conversation"]], "llama_2 (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[46, "lmflow.utils.llava_conversation_lib.SeparatorStyle.LLAMA_2"]], "mpt (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[46, "lmflow.utils.llava_conversation_lib.SeparatorStyle.MPT"]], "plain (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[46, "lmflow.utils.llava_conversation_lib.SeparatorStyle.PLAIN"]], "single (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[46, "lmflow.utils.llava_conversation_lib.SeparatorStyle.SINGLE"]], "separatorstyle (class in lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.SeparatorStyle"]], "two (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[46, "lmflow.utils.llava_conversation_lib.SeparatorStyle.TWO"]], "append_message() (lmflow.utils.llava_conversation_lib.conversation method)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.append_message"]], "conv_llama_2 (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_llama_2"]], "conv_llava_llama_2 (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_llava_llama_2"]], "conv_llava_plain (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_llava_plain"]], "conv_llava_v0 (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_llava_v0"]], "conv_llava_v0_mmtag (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_llava_v0_mmtag"]], "conv_llava_v1 (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_llava_v1"]], "conv_llava_v1_mmtag (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_llava_v1_mmtag"]], "conv_mpt (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_mpt"]], "conv_templates (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_templates"]], "conv_vicuna_v0 (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_vicuna_v0"]], "conv_vicuna_v1 (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.conv_vicuna_v1"]], "copy() (lmflow.utils.llava_conversation_lib.conversation method)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.copy"]], "default_conversation (in module lmflow.utils.llava_conversation_lib)": [[46, "lmflow.utils.llava_conversation_lib.default_conversation"]], "dict() (lmflow.utils.llava_conversation_lib.conversation method)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.dict"]], "get_images() (lmflow.utils.llava_conversation_lib.conversation method)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.get_images"]], "get_prompt() (lmflow.utils.llava_conversation_lib.conversation method)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.get_prompt"]], "lmflow.utils.llava_conversation_lib": [[46, "module-lmflow.utils.llava_conversation_lib"]], "messages (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.messages"]], "offset (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.offset"]], "roles (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.roles"]], "sep (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.sep"]], "sep2 (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.sep2"]], "sep_style (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.sep_style"]], "skip_next (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.skip_next"]], "system (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.system"]], "to_gradio_chatbot() (lmflow.utils.llava_conversation_lib.conversation method)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.to_gradio_chatbot"]], "version (lmflow.utils.llava_conversation_lib.conversation attribute)": [[46, "lmflow.utils.llava_conversation_lib.Conversation.version"]], "adapt_llava_model_to_lmflow_type() (in module lmflow.utils.multimodal)": [[47, "lmflow.utils.multimodal.adapt_llava_model_to_lmflow_type"]], "lmflow.utils.multimodal": [[47, "module-lmflow.utils.multimodal"]], "load_llava_pretrain_model() (in module lmflow.utils.multimodal)": [[47, "lmflow.utils.multimodal.load_llava_pretrain_model"]], "update_custom_config() (in module lmflow.utils.multimodal)": [[47, "lmflow.utils.multimodal.update_custom_config"]], "lmflow.utils.position_interpolation": [[48, "module-lmflow.utils.position_interpolation"]], "condenserotaryembedding (class in lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch)": [[49, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding"]], "forward() (lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.condenserotaryembedding method)": [[49, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding.forward"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[49, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch"]], "replace_llama_with_condense() (in module lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch)": [[49, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.replace_llama_with_condense"]], "__version__ (in module lmflow.version)": [[50, "lmflow.version.__version__"]], "lmflow.version": [[50, "module-lmflow.version"]]}})